{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83df52ac-a343-49ec-83bc-16b8c91b9dd0",
   "metadata": {},
   "source": [
    "Purpose of this notebook is to use LORA (aka Low Rank Adaptation method) and finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86420020-5a69-4a3b-a6be-6ce274be8bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m pip install -q datasets peft evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54679b61-b9f8-4a5c-a846-0f11a1946d49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !python -m pip uninstall -y pyarrow datasets ibis-framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59bd4be8-9789-447d-880a-264763f117fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !python -m pip install pyarrow>=15.0.0 datasets peft evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e05e4a8e-313a-48e5-9cb6-16ec108133bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !python -m pip show pyarrow datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28a5ba79-b2c6-4ab7-b0dd-940eeab27cca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !python -m pip install pyarrow>=15.0.0 datasets peft evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96c683dd-30bd-448a-ada9-bc4562b61663",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/new_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "\n",
    "from transformers import (AutoTokenizer,\n",
    "                         AutoConfig,\n",
    "                         AutoModelForSequenceClassification,\n",
    "                         DataCollatorWithPadding,\n",
    "                         TrainingArguments,\n",
    "                         Trainer)\n",
    "\n",
    "from peft import PeftModel, PeftConfig, get_peft_model, LoraConfig\n",
    "import evaluate\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bdb5089-e82b-440e-acd5-a2e136755a6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.nn.functional import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f32ae2ac-7f08-4fc4-baa7-10a7ccbcf800",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'mps'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e512cf-4776-4278-9612-ec5c8be44f80",
   "metadata": {},
   "source": [
    "#### Base Model (mobileBERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1dc1475-55e2-42ca-a881-8f33e475f41c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MobileBertForSequenceClassification were not initialized from the model checkpoint at google/mobilebert-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint = 'google/mobilebert-uncased'\n",
    "id2label = {0: 'information_intent',\n",
    "            1: 'yelp_intent',\n",
    "            2: 'navigation_intent',\n",
    "            3: 'travel_intent',\n",
    "            4: 'purchase_intent',\n",
    "            5: 'weather_intent',\n",
    "            6: 'translation_intent',\n",
    "            7: 'unknown'}\n",
    "label2id = {label:id for id,label in id2label.items()}\n",
    "\n",
    "\n",
    "# generate classification model from model chckpoints\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    num_labels=8,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbeaa99b-10c2-44ed-8d21-08ed2b3990bd",
   "metadata": {},
   "source": [
    "#### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81eb7dac-565f-4247-b42d-fe2d7675ec60",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201426\n",
      "target\n",
      "information_intent    120879\n",
      "yelp_intent            33274\n",
      "navigation_intent      14332\n",
      "weather_intent         13749\n",
      "purchase_intent         7892\n",
      "travel_intent           6684\n",
      "unknown                 2322\n",
      "translation_intent      2294\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what is the benefits of six sigma process?</td>\n",
       "      <td>information_intent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cheap professional cleaning service</td>\n",
       "      <td>yelp_intent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>house cleaners and apartment cleaning</td>\n",
       "      <td>yelp_intent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what define white as a race</td>\n",
       "      <td>information_intent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what is a nigp commodity code</td>\n",
       "      <td>information_intent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mrui, Hawai</td>\n",
       "      <td>travel_intent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>wood floor buckling repair</td>\n",
       "      <td>yelp_intent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>venereal disease meaning</td>\n",
       "      <td>information_intent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>what is a single-subject or single-system design</td>\n",
       "      <td>information_intent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>how to cite quotes from a book</td>\n",
       "      <td>information_intent</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sequence              target\n",
       "0        what is the benefits of six sigma process?  information_intent\n",
       "1               cheap professional cleaning service         yelp_intent\n",
       "2             house cleaners and apartment cleaning         yelp_intent\n",
       "3                       what define white as a race  information_intent\n",
       "4                     what is a nigp commodity code  information_intent\n",
       "5                                       Mrui, Hawai       travel_intent\n",
       "6                        wood floor buckling repair         yelp_intent\n",
       "7                          venereal disease meaning  information_intent\n",
       "8  what is a single-subject or single-system design  information_intent\n",
       "9                    how to cite quotes from a book  information_intent"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/marco_train_v7.csv\")\n",
    "print(len(df))\n",
    "print(df['target'].value_counts())\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb24484d-7380-49b6-b67f-5b645e46cf49",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    201426.000000\n",
      "mean         28.749134\n",
      "std          11.268303\n",
      "min           3.000000\n",
      "10%          16.000000\n",
      "20%          19.000000\n",
      "25%          21.000000\n",
      "30%          22.000000\n",
      "40%          25.000000\n",
      "50%          28.000000\n",
      "60%          31.000000\n",
      "70%          34.000000\n",
      "75%          35.000000\n",
      "80%          37.000000\n",
      "90%          43.000000\n",
      "95%          48.000000\n",
      "98%          54.000000\n",
      "99%          59.000000\n",
      "99.5%        65.000000\n",
      "99.8%        78.000000\n",
      "99.9%        91.575000\n",
      "max         193.000000\n",
      "Name: sequence, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(df['sequence'].apply(len).describe(percentiles=[.1, .2, .25, .3, .4, .5, .6, .7, .75, .8, .9, .95, .98, .99, .995, .998, .999]))\n",
    "df['sequence'].apply(len).hist(bins=25);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "082fb996-037b-4353-8739-7047d6142f69",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>how many constitutional amendments have been ratified since its ratification ?</td>\n",
       "      <td>information_intent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>which of the following protein classes are not found as membrane proteins?</td>\n",
       "      <td>information_intent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>dilated ascending thoracic aorta and type b dissection definition</td>\n",
       "      <td>information_intent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>which molecules show an appropriate number of bonds around each carbon atom?select the three tha...</td>\n",
       "      <td>information_intent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>one difference between mitosis and meiosis is that cells entering meiosis</td>\n",
       "      <td>information_intent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200989</th>\n",
       "      <td>what kind of beauty is lord byron defining in she walks in beauty</td>\n",
       "      <td>information_intent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201133</th>\n",
       "      <td>which of the following is a fundamental consideration to examine when task organizing a force?</td>\n",
       "      <td>information_intent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201283</th>\n",
       "      <td>which css attribute would change an element's font color to blue?</td>\n",
       "      <td>information_intent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201393</th>\n",
       "      <td>american continental insurance company aetna, customer care phone number</td>\n",
       "      <td>navigation_intent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201410</th>\n",
       "      <td>Where to find the best fried chicken in San Francisco, California?</td>\n",
       "      <td>yelp_intent</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1074 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                   sequence  \\\n",
       "233                          how many constitutional amendments have been ratified since its ratification ?   \n",
       "253                              which of the following protein classes are not found as membrane proteins?   \n",
       "353                                       dilated ascending thoracic aorta and type b dissection definition   \n",
       "363     which molecules show an appropriate number of bonds around each carbon atom?select the three tha...   \n",
       "666                               one difference between mitosis and meiosis is that cells entering meiosis   \n",
       "...                                                                                                     ...   \n",
       "200989                                    what kind of beauty is lord byron defining in she walks in beauty   \n",
       "201133       which of the following is a fundamental consideration to examine when task organizing a force?   \n",
       "201283                                    which css attribute would change an element's font color to blue?   \n",
       "201393                             american continental insurance company aetna, customer care phone number   \n",
       "201410                                   Where to find the best fried chicken in San Francisco, California?   \n",
       "\n",
       "                    target  \n",
       "233     information_intent  \n",
       "253     information_intent  \n",
       "353     information_intent  \n",
       "363     information_intent  \n",
       "666     information_intent  \n",
       "...                    ...  \n",
       "200989  information_intent  \n",
       "201133  information_intent  \n",
       "201283  information_intent  \n",
       "201393   navigation_intent  \n",
       "201410         yelp_intent  \n",
       "\n",
       "[1074 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 100)\n",
    "df.loc[df['sequence'].apply(lambda text: len(text) > 64)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7e0d5f3-b927-477e-ac5b-5e05fce4835b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/new_env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          sequence  token_length\n",
      "0       what is the benefits of six sigma process?            11\n",
      "1              cheap professional cleaning service             6\n",
      "2            house cleaners and apartment cleaning             8\n",
      "3                      what define white as a race             8\n",
      "4                    what is a nigp commodity code             9\n",
      "...                                            ...           ...\n",
      "201421          cheapest taqueria el amigo waltham            12\n",
      "201422        how many micro bitcoins in a bitcoin            13\n",
      "201423                             define pigments             5\n",
      "201424             weather in crested butte in may             8\n",
      "201425      where is the iberian peninsula located             8\n",
      "\n",
      "[201426 rows x 2 columns]\n",
      "Max token length: 55\n",
      "Average token length: 8.108238261197661\n",
      "90th percentile token length: 11.0\n",
      "95th percentile token length: 13.0\n",
      "98th percentile token length: 14.0\n",
      "99th percentile token length: 15.0\n",
      "99.5th percentile token length: 16.0\n",
      "99.9th percentile token length: 21.0\n"
     ]
    }
   ],
   "source": [
    "# create tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, add_prefix_space=True)\n",
    "\n",
    "token_lengths = []\n",
    "for sequence in df['sequence'].values:\n",
    "    tokens = tokenizer(sequence, truncation=False)['input_ids']  # Get tokenized input IDs\n",
    "    token_lengths.append(len(tokens))\n",
    "\n",
    "# Create a DataFrame for analysis\n",
    "temp_df = pd.DataFrame({'sequence': df['sequence'].values, 'token_length': token_lengths})\n",
    "\n",
    "# Display token lengths\n",
    "print(temp_df)\n",
    "\n",
    "# Optional: Analyze token lengths for deciding the best max_length\n",
    "print(f\"Max token length: {temp_df['token_length'].max()}\")\n",
    "print(f\"Average token length: {temp_df['token_length'].mean()}\")\n",
    "print(f\"90th percentile token length: {temp_df['token_length'].quantile(0.9)}\")\n",
    "print(f\"95th percentile token length: {temp_df['token_length'].quantile(0.95)}\")\n",
    "print(f\"98th percentile token length: {temp_df['token_length'].quantile(0.98)}\")\n",
    "print(f\"99th percentile token length: {temp_df['token_length'].quantile(0.99)}\")\n",
    "print(f\"99.5th percentile token length: {temp_df['token_length'].quantile(0.995)}\")\n",
    "print(f\"99.9th percentile token length: {temp_df['token_length'].quantile(0.999)}\")\n",
    "\n",
    "del temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13e6c934-fdc6-4d28-9c87-69eec74e5beb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    120879\n",
      "1     33274\n",
      "2     14332\n",
      "5     13749\n",
      "4      7892\n",
      "3      6684\n",
      "7      2322\n",
      "6      2294\n",
      "Name: count, dtype: int64\n",
      "Size of sampled_df = 201426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_287165/1383443563.py:15: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sampled_df = df.groupby('target', group_keys=False).apply(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>target</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what does a degree in public health do</td>\n",
       "      <td>information_intent</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>where is hochatown oklahoma</td>\n",
       "      <td>information_intent</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what is the formula for frequency</td>\n",
       "      <td>information_intent</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nfl patriots schedule</td>\n",
       "      <td>information_intent</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>define tundra climate</td>\n",
       "      <td>information_intent</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 sequence              target  label\n",
       "0  what does a degree in public health do  information_intent      0\n",
       "1             where is hochatown oklahoma  information_intent      0\n",
       "2       what is the formula for frequency  information_intent      0\n",
       "3                   nfl patriots schedule  information_intent      0\n",
       "4                   define tundra climate  information_intent      0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select only a sample from the actual data\n",
    "\n",
    "sampling_percentages = {\n",
    "    'information_intent': 1.0,   # 100% sampling for information_intent\n",
    "    'yelp_intent': 1.0,          # 100% sampling for yelp_intent\n",
    "    'weather_intent': 1.0,       # 100% sampling for weather_intent\n",
    "    'navigation_intent': 1.0,    # 100% sampling for navigation_intent\n",
    "    'purchase_intent': 1.0,      # 100% sampling for purchase_intent\n",
    "    'translation_intent': 1.0,   # 100% sampling for translation_intent\n",
    "    'travel_intent': 1.0,        # 100% sampling for travel_intent\n",
    "    'unknown': 1.0               # 100% sampling for unknown\n",
    "}\n",
    "\n",
    "# Sample from each target group based on the defined percentages\n",
    "sampled_df = df.groupby('target', group_keys=False).apply(\n",
    "    lambda x: x.sample(frac=sampling_percentages.get(x.name, 1.0))\n",
    ").reset_index(drop=True)\n",
    "\n",
    "sampled_df['label'] = sampled_df['target'].map(label2id)\n",
    "# sampled_df = sampled_df.rename(columns={'target': 'label'})\n",
    "\n",
    "print(sampled_df['label'].value_counts())\n",
    "print(f\"Size of sampled_df = {len(sampled_df)}\")\n",
    "sampled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8dadb9a2-6184-4e50-bf21-8063e31edbb1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['sequence', 'target', 'label'],\n",
      "        num_rows: 191354\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['sequence', 'target', 'label'],\n",
      "        num_rows: 10072\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Split the DataFrame into train and validation sets\n",
    "train_df, val_df = train_test_split(sampled_df, test_size=0.05, random_state=42, stratify=sampled_df['label'])\n",
    "\n",
    "# Step 2: Convert Pandas DataFrames to Hugging Face Datasets\n",
    "train_dataset = Dataset.from_pandas(train_df, preserve_index=False)\n",
    "val_dataset = Dataset.from_pandas(val_df, preserve_index=False)\n",
    "\n",
    "# Step 3: Create a DatasetDict\n",
    "dataset_dict = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'validation': val_dataset\n",
    "})\n",
    "\n",
    "# Step 4: Verify the structure of DatasetDict\n",
    "print(dataset_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0613b1e7-e4ec-4b18-91a2-2648c42a91b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    114835\n",
       "1     31610\n",
       "2     13615\n",
       "5     13062\n",
       "4      7497\n",
       "3      6350\n",
       "7      2206\n",
       "6      2179\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68d476d6-4aa2-4180-889b-49f8e5251219",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    6044\n",
       "1    1664\n",
       "2     717\n",
       "5     687\n",
       "4     395\n",
       "3     334\n",
       "7     116\n",
       "6     115\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ae60f7-3f28-4d95-bee7-28d05b68566f",
   "metadata": {},
   "source": [
    "#### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17cb2d99-4f2f-4caa-8f1f-747fbc9c9082",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# add pad token if none exists\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# tokenize function\n",
    "def tokenize_function(examples):\n",
    "    # extract text\n",
    "    text = examples[\"sequence\"]\n",
    "\n",
    "    # tokenize and truncate text\n",
    "    tokenizer.truncation_side = \"right\"\n",
    "    tokenized_inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        padding=True,  # Pad the sequences to the longest in the batch\n",
    "        max_length=64\n",
    "    )\n",
    "    return tokenized_inputs\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d52d8863-7705-40d2-a6b4-26b1865f5c1c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 191354/191354 [00:07<00:00, 24857.92 examples/s]\n",
      "Map: 100%|██████████| 10072/10072 [00:00<00:00, 26980.25 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sequence', 'target', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 191354\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sequence', 'target', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 10072\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset = dataset_dict.map(tokenize_function, batched=True)\n",
    "# tokenized_dataset = tokenized_dataset.map(fix_labels)\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56166c5b-958c-4921-961a-7e42c1ef37d7",
   "metadata": {},
   "source": [
    "#### Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d481d862-dfe6-4635-9d0c-7c827a2155f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    logits, labels = p\n",
    "    predictions = np.argmax(logits, axis=1)\n",
    "    # Combine metrics\n",
    "    accuracy_metric = evaluate.load(\"accuracy\")\n",
    "    precision_metric = evaluate.load(\"precision\")\n",
    "    recall_metric = evaluate.load(\"recall\")\n",
    "    f1_metric = evaluate.load(\"f1\")\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_metric.compute(predictions=predictions, references=labels)\n",
    "    precision = precision_metric.compute(predictions=predictions, references=labels, average=\"weighted\")\n",
    "    recall = recall_metric.compute(predictions=predictions, references=labels, average=\"weighted\")\n",
    "    f1 = f1_metric.compute(predictions=predictions, references=labels, average=\"weighted\")\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy[\"accuracy\"],\n",
    "        \"precision\": precision[\"precision\"],\n",
    "        \"recall\": recall[\"recall\"],\n",
    "        \"f1\": f1[\"f1\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f08d8464-0714-4021-a266-9ceb64f36f0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ### Evaluate untrained model\n",
    "\n",
    "# text_list = [\n",
    "#     'floor repair cost',\n",
    "#     'denture fix',\n",
    "#     'who is the us president',\n",
    "#     'italian food',\n",
    "#     'sandwiches in seattle',\n",
    "#     'seattle weather',\n",
    "#     'weather seattle',\n",
    "#     'boston wether',\n",
    "#     'Boston wether',\n",
    "#     'weather boston',\n",
    "#     'weather Boston',\n",
    "#     'Weather Boston',\n",
    "#     'weathr boston',\n",
    "#     'seattle weathr',\n",
    "#     'apple macbook price',\n",
    "#     'sf sushi',\n",
    "#     'sf ramen',\n",
    "#     'seattle sushi',\n",
    "#     'seattle ramen',\n",
    "#     'sushi sf',\n",
    "#     'ramen sf',\n",
    "#     'chase bank login',\n",
    "#     'passport application',\n",
    "#     'walm',\n",
    "#     'footbal',\n",
    "#     'movers quote','its sushi', 'average house cleaning rates', 'fun things to do', 'foster gwin', 'go karts', 'facial', 'donuts',\n",
    "#     'via carota', 'tomi jazz', 'mun korean steakhouse', 'la pecora bianca', 'birria tacos', 'bank of america', 'bungee fitness',\n",
    "#     'allien', 'proposa', 'wather', 'big city', 'orlando bloom', 'banana', 'lenght',\n",
    "# ]\n",
    "\n",
    "# print(\"Untrained model predictions:\")\n",
    "# print(\"----------------------------\")\n",
    "# predictions = []\n",
    "# logits_list = []\n",
    "# for text in text_list:\n",
    "#     inputs = tokenizer.encode(text, return_tensors=\"pt\")\n",
    "#     logits = model(inputs).logits\n",
    "#     prediction = torch.argmax(logits, dim=1).item()\n",
    "#     predictions.append(prediction)\n",
    "#     print(text + \" -> \" + id2label[prediction])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bfb5ad-391d-42da-bcf5-d62e39642225",
   "metadata": {},
   "source": [
    "#### Model finetuning with LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cece8cd8-b017-4f80-9d9a-713041270fc2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 200,712 || all params: 24,786,704 || trainable%: 0.8098\n"
     ]
    }
   ],
   "source": [
    "peft_config = LoraConfig(task_type=\"SEQ_CLS\",\n",
    "                         r=16, # intrinsic rank of trainable weight matrix\n",
    "                         lora_alpha=32, # similar to learning_rate\n",
    "                         lora_dropout=0.01, # probability of dropout nodes\n",
    "                         target_modules=['attention.self.query', 'attention.self.key']) # LoRA is applied to query & key layer\n",
    "\n",
    "\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "93c9ac1c-cd57-4173-b208-78831d9c4f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name, module in model.named_modules():\n",
    "#     print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ccdcde-6b2c-499d-a185-d04dbd1b6ba7",
   "metadata": {},
   "source": [
    "#### Define hyper parameters and training arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "84297802-ae8a-4fef-882a-7d7145de72bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "lr = 1e-4\n",
    "batch_size = 16\n",
    "num_epochs = 6\n",
    "\n",
    "# training args\n",
    "training_args = TrainingArguments(\n",
    "    # output_dir=model_checkpoint + \"-lora-intent-classification-v3\",\n",
    "    output_dir=\"mobilebert-uncased\" + \"-lora-intent-classification-v7\",\n",
    "    learning_rate=lr,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=num_epochs,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    # warmup_steps=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "615cdb83-edc7-409a-a929-6c370c8aa9e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model, \n",
    "    args=training_args, # Hyperparamaters\n",
    "    train_dataset=tokenized_dataset[\"train\"], # training data\n",
    "    eval_dataset=tokenized_dataset[\"validation\"], # validation data\n",
    "    tokenizer=tokenizer, # tokenizer\n",
    "    data_collator=data_collator, # dynamic sequence padding\n",
    "    compute_metrics=compute_metrics,  # model perfomance evaluation metric\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=4)]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f9fde457-1a0d-4552-b6fa-1c0642349972",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='71760' max='71760' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [71760/71760 2:09:26, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>33.990200</td>\n",
       "      <td>14.665943</td>\n",
       "      <td>0.916402</td>\n",
       "      <td>0.914308</td>\n",
       "      <td>0.916402</td>\n",
       "      <td>0.915002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>79.863200</td>\n",
       "      <td>8.076523</td>\n",
       "      <td>0.936954</td>\n",
       "      <td>0.935874</td>\n",
       "      <td>0.936954</td>\n",
       "      <td>0.935775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>79.019000</td>\n",
       "      <td>5.699135</td>\n",
       "      <td>0.946088</td>\n",
       "      <td>0.945333</td>\n",
       "      <td>0.946088</td>\n",
       "      <td>0.945508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>27.499600</td>\n",
       "      <td>1.473685</td>\n",
       "      <td>0.942415</td>\n",
       "      <td>0.942223</td>\n",
       "      <td>0.942415</td>\n",
       "      <td>0.942057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>13.533700</td>\n",
       "      <td>0.768880</td>\n",
       "      <td>0.948967</td>\n",
       "      <td>0.948049</td>\n",
       "      <td>0.948967</td>\n",
       "      <td>0.948176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.958600</td>\n",
       "      <td>0.327371</td>\n",
       "      <td>0.950556</td>\n",
       "      <td>0.949603</td>\n",
       "      <td>0.950556</td>\n",
       "      <td>0.949863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=71760, training_loss=938.2985988178913, metrics={'train_runtime': 7766.6143, 'train_samples_per_second': 147.828, 'train_steps_per_second': 9.24, 'total_flos': 5739157493809920.0, 'train_loss': 938.2985988178913, 'epoch': 6.0})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1da3c5f1-ef7f-4ca1-9792-4879b621f267",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# trainer.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "92c14f7e-2087-4c02-a572-5af73b4c9e92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_list = [\n",
    "    'floor repair cost',\n",
    "    'denture implant cost',\n",
    "    'who is the us president',\n",
    "    'italian food',\n",
    "    'sandwiches in seattle',\n",
    "    'seattle weather',\n",
    "    'weather seattle',\n",
    "    'boston wether',\n",
    "    'Boston wether',\n",
    "    'weather boston',\n",
    "    'weather Boston',\n",
    "    'Weather Boston',\n",
    "    'weathr boston',\n",
    "    'seattle weathr',\n",
    "    'apple macbook price',\n",
    "    'sf sushi',\n",
    "    'sf ramen',\n",
    "    'seattle sushi',\n",
    "    'seattle ramen',\n",
    "    'sushi sf',\n",
    "    'ramen sf',\n",
    "    'chase bank login',\n",
    "    'passport application',\n",
    "    'movers quote','its sushi', 'average house cleaning rates', 'fun things to do', 'foster gwin', 'go karts', 'facial', 'donuts',\n",
    "    'via carota', 'tomi jazz', 'mun korean steakhouse', 'la pecora bianca', 'birria tacos', 'bank of america', 'bungee fitness',\n",
    "    'best smartphone',\n",
    "    'sushi sf',\n",
    "    'ramen sf',\n",
    "    'sushi',\n",
    "    'ramen',\n",
    "    'footbal',\n",
    "    'breaking bad',\n",
    "    'walm',\n",
    "    'top gun maverick',\n",
    "    'clean pape',\n",
    "    'paws scor',\n",
    "    'cristiano ronaldo',\n",
    "    'fastfood',\n",
    "    'inte',\n",
    "    'potatos',\n",
    "    'visionare',\n",
    "    'allien',\n",
    "    'proposa',\n",
    "    'wather',\n",
    "    'big city',\n",
    "    'orlando bloom',\n",
    "    'banana',\n",
    "    'lenght',\n",
    "    'cafe ca',\n",
    "    'arcade',\n",
    "    'bagels',\n",
    "    'bank of america',\n",
    "    'bowling',\n",
    "    'cupcakes',\n",
    "    'electrician', 'electricians', 'best electrician', 'best electricians', 'popular electricians',\n",
    "    'karaoke',\n",
    "    'korean bbq',\n",
    "    'laser tag',\n",
    "    'pilates',\n",
    "    'sports bar',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "15d874c9-e652-4c17-8a54-11d94710debb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "floor repair cost -> yelp_intent:  0.9999886751174927\n",
      "denture implant cost -> yelp_intent:  0.9304097890853882\n",
      "who is the us president -> information_intent:  0.9999076128005981\n",
      "italian food -> yelp_intent:  0.9821021556854248\n",
      "sandwiches in seattle -> yelp_intent:  0.9847724437713623\n",
      "seattle weather -> weather_intent:  0.9998944997787476\n",
      "weather seattle -> weather_intent:  0.9999699592590332\n",
      "boston wether -> weather_intent:  0.8431703448295593\n",
      "Boston wether -> weather_intent:  0.8431703448295593\n",
      "weather boston -> weather_intent:  0.999985933303833\n",
      "weather Boston -> weather_intent:  0.999985933303833\n",
      "Weather Boston -> weather_intent:  0.999985933303833\n",
      "weathr boston -> weather_intent:  0.9999779462814331\n",
      "seattle weathr -> weather_intent:  0.9999904632568359\n",
      "apple macbook price -> purchase_intent:  0.9962782263755798\n",
      "sf sushi -> yelp_intent:  0.9695122838020325\n",
      "sf ramen -> yelp_intent:  0.9479253888130188\n",
      "seattle sushi -> yelp_intent:  0.9816707372665405\n",
      "seattle ramen -> yelp_intent:  0.901893138885498\n",
      "sushi sf -> yelp_intent:  0.9510340094566345\n",
      "ramen sf -> yelp_intent:  0.9724605679512024\n",
      "chase bank login -> navigation_intent:  0.996920108795166\n",
      "passport application -> navigation_intent:  0.9247398972511292\n",
      "movers quote -> yelp_intent:  0.7618657350540161\n",
      "its sushi -> yelp_intent:  0.9966803789138794\n",
      "average house cleaning rates -> yelp_intent:  0.9998249411582947\n",
      "fun things to do -> information_intent:  0.9989758729934692\n",
      "foster gwin -> travel_intent:  0.2423482984304428\n",
      "go karts -> information_intent:  0.9999998807907104\n",
      "facial -> information_intent:  0.9467757940292358\n",
      "donuts -> yelp_intent:  0.9420908689498901\n",
      "via carota -> yelp_intent:  0.7679468989372253\n",
      "tomi jazz -> yelp_intent:  0.5349456667900085\n",
      "mun korean steakhouse -> yelp_intent:  0.9998230338096619\n",
      "la pecora bianca -> yelp_intent:  0.9682960510253906\n",
      "birria tacos -> yelp_intent:  0.8375977873802185\n",
      "bank of america -> yelp_intent:  0.6579618453979492\n",
      "bungee fitness -> yelp_intent:  0.9539031386375427\n",
      "best smartphone -> purchase_intent:  0.9962849617004395\n",
      "sushi sf -> yelp_intent:  0.9510340094566345\n",
      "ramen sf -> yelp_intent:  0.9724605679512024\n",
      "sushi -> yelp_intent:  0.9385586380958557\n",
      "ramen -> yelp_intent:  0.9702029824256897\n",
      "footbal -> yelp_intent:  0.812846302986145\n",
      "breaking bad -> yelp_intent:  0.5361633896827698\n",
      "walm -> yelp_intent:  0.46926113963127136\n",
      "top gun maverick -> yelp_intent:  0.6874262690544128\n",
      "clean pape -> yelp_intent:  0.9994452595710754\n",
      "paws scor -> yelp_intent:  0.3809022307395935\n",
      "cristiano ronaldo -> information_intent:  0.9887937903404236\n",
      "fastfood -> purchase_intent:  0.7275564074516296\n",
      "inte -> unknown:  0.8206241726875305\n",
      "potatos -> purchase_intent:  0.5277106165885925\n",
      "visionare -> information_intent:  0.3556281626224518\n",
      "allien -> unknown:  0.40468621253967285\n",
      "proposa -> yelp_intent:  0.8796427845954895\n",
      "wather -> unknown:  0.3101065158843994\n",
      "big city -> information_intent:  0.5532987713813782\n",
      "orlando bloom -> information_intent:  0.820439338684082\n",
      "banana -> yelp_intent:  0.8666567206382751\n",
      "lenght -> travel_intent:  0.7071148157119751\n",
      "cafe ca -> yelp_intent:  0.9976315498352051\n",
      "arcade -> yelp_intent:  0.5822463035583496\n",
      "bagels -> yelp_intent:  0.9065232276916504\n",
      "bank of america -> yelp_intent:  0.6579618453979492\n",
      "bowling -> yelp_intent:  0.978693962097168\n",
      "cupcakes -> purchase_intent:  0.7694507837295532\n",
      "electrician -> information_intent:  0.7281216382980347\n",
      "electricians -> yelp_intent:  0.5461614727973938\n",
      "best electrician -> yelp_intent:  0.9320979118347168\n",
      "best electricians -> yelp_intent:  0.9594696760177612\n",
      "popular electricians -> yelp_intent:  0.5538366436958313\n",
      "karaoke -> yelp_intent:  0.49948883056640625\n",
      "korean bbq -> yelp_intent:  0.9923018217086792\n",
      "laser tag -> yelp_intent:  0.6817433834075928\n",
      "pilates -> yelp_intent:  0.721386730670929\n",
      "sports bar -> yelp_intent:  0.9708926677703857\n"
     ]
    }
   ],
   "source": [
    "trainer.model.eval()\n",
    "with torch.no_grad():\n",
    "    for text in text_list:\n",
    "        inputs = tokenizer.encode(text, return_tensors=\"pt\").to(device)\n",
    "        logits = trainer.model(inputs).logits\n",
    "        prediction = torch.argmax(logits, dim=1).item()\n",
    "        probabilities = softmax(logits, dim=1)\n",
    "        prediction_probability = probabilities[0, prediction].item()\n",
    "        print(text + \" -> \" + id2label[prediction] + \": \", prediction_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "66aae059-b207-43d5-8a78-a76901550c8a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 3.4M\n",
      "-rw-r--r-- 1 jupyter jupyter 5.0K Nov 29 20:54 README.md\n",
      "-rw-r--r-- 1 jupyter jupyter  706 Nov 29 20:54 adapter_config.json\n",
      "-rw-r--r-- 1 jupyter jupyter 798K Nov 29 20:54 adapter_model.safetensors\n",
      "-rw-r--r-- 1 jupyter jupyter 1.7M Nov 29 20:54 optimizer.pt\n",
      "-rw-r--r-- 1 jupyter jupyter  14K Nov 29 20:54 rng_state.pth\n",
      "-rw-r--r-- 1 jupyter jupyter 1.1K Nov 29 20:54 scheduler.pt\n",
      "-rw-r--r-- 1 jupyter jupyter  125 Nov 29 20:54 special_tokens_map.json\n",
      "-rw-r--r-- 1 jupyter jupyter 695K Nov 29 20:54 tokenizer.json\n",
      "-rw-r--r-- 1 jupyter jupyter 1.3K Nov 29 20:54 tokenizer_config.json\n",
      "-rw-r--r-- 1 jupyter jupyter  28K Nov 29 20:54 trainer_state.json\n",
      "-rw-r--r-- 1 jupyter jupyter 5.2K Nov 29 20:54 training_args.bin\n",
      "-rw-r--r-- 1 jupyter jupyter 227K Nov 29 20:54 vocab.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!ls -lh mobilebert-uncased-lora-intent-classification-v7/checkpoint-71760"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c08157f-ff0c-46a3-aa0d-f04493a71d36",
   "metadata": {},
   "source": [
    "#### Load the LoRA model from checkpoint after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "041cee58-787b-430c-a9c4-c4aadcf87a58",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MobileBertForSequenceClassification were not initialized from the model checkpoint at google/mobilebert-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ -3.1562,   8.0883,  -4.3224, -10.1520,   1.9380,  -7.3656, -11.7488,\n",
      "          -5.7316]], grad_fn=<AddmmBackward0>)\n",
      "1 yelp_intent\n",
      "tensor([[0., 1., 0., 0., 0., 0., 0., 0.]], grad_fn=<RoundBackward0>)\n"
     ]
    }
   ],
   "source": [
    "id2label = {0: 'information_intent',\n",
    "            1: 'yelp_intent',\n",
    "            2: 'navigation_intent',\n",
    "            3: 'travel_intent',\n",
    "            4: 'purchase_intent',\n",
    "            5: 'weather_intent',\n",
    "            6: 'translation_intent',\n",
    "            7: 'unknown'}\n",
    "label2id = {label:id for id,label in id2label.items()}\n",
    "\n",
    "\n",
    "output_dir = \"mobilebert-uncased-lora-intent-classification-v7/checkpoint-71760\"\n",
    "\n",
    "# Load the tokenizer (from the output directory)\n",
    "tokenizer = AutoTokenizer.from_pretrained(output_dir, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=64)\n",
    "\n",
    "# Load the base model from the original checkpoint (base pre-trained model)\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained('google/mobilebert-uncased', num_labels=8, id2label=id2label, label2id=label2id)\n",
    "\n",
    "# Load the LoRA configuration and model\n",
    "peft_config = PeftConfig.from_pretrained(output_dir)\n",
    "lora_model = PeftModel.from_pretrained(base_model, output_dir)\n",
    "\n",
    "# Step 3: Save the combined model to a directory\n",
    "save_directory = \"tmp/mobilebert_lora_combined_model/\"\n",
    "lora_model.save_pretrained(save_directory)  # Save base model + LoRA weights\n",
    "\n",
    "# Now the `lora_model` contains both the base model and the LoRA weights.\n",
    "lora_model.eval()\n",
    "\n",
    "# Example inference\n",
    "inputs = tokenizer([\"looking for home cleaning \"], return_tensors=\"pt\")\n",
    "outputs = lora_model(**inputs)\n",
    "logits = outputs.logits\n",
    "print(logits)\n",
    "\n",
    "\n",
    "prediction = torch.argmax(logits, dim=1).item()\n",
    "print(prediction, id2label[prediction])\n",
    "probabilities = torch.softmax(logits, dim=1)\n",
    "rounded_probabilities = torch.round(probabilities)\n",
    "print(rounded_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d5f259a5-9032-4614-b0fc-b6c685ea250e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MobileBertForSequenceClassification were not initialized from the model checkpoint at google/mobilebert-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('tmp/mobilebert_lora_combined_model/tokenizer_config.json',\n",
       " 'tmp/mobilebert_lora_combined_model/special_tokens_map.json',\n",
       " 'tmp/mobilebert_lora_combined_model/vocab.txt',\n",
       " 'tmp/mobilebert_lora_combined_model/added_tokens.json',\n",
       " 'tmp/mobilebert_lora_combined_model/tokenizer.json')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "# Step 1: Load the base model (DistilBERT)\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained('google/mobilebert-uncased', num_labels=8, id2label=id2label, label2id=label2id)\n",
    "\n",
    "# Step 2: Load the LoRA adapter weights\n",
    "output_dir = \"mobilebert-uncased-lora-intent-classification-v7/checkpoint-71760\"\n",
    "peft_config = PeftConfig.from_pretrained(output_dir)\n",
    "lora_model = PeftModel.from_pretrained(base_model, output_dir)\n",
    "\n",
    "# Step 3: Merge LoRA weights into the base model\n",
    "# After this, the model will have both base and LoRA weights applied\n",
    "merged_model = lora_model.merge_and_unload()\n",
    "\n",
    "# Step 4: Save the full model (base model + LoRA weights)\n",
    "save_directory = \"tmp/mobilebert_lora_combined_model/\"\n",
    "merged_model.save_pretrained(save_directory)\n",
    "tokenizer = AutoTokenizer.from_pretrained(output_dir)  # Load the tokenizer\n",
    "tokenizer.save_pretrained(save_directory)  # Save the tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7eb33ea5-05c4-4417-8c86-05782471d680",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !huggingface-cli whoami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "75982821-faaf-45ba-9936-26f1c275f78f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|██████████| 98.5M/98.5M [00:02<00:00, 34.5MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/Mozilla/mobilebert-uncased-finetuned-LoRA-intent-classifier/commit/038a864771e9afe4c0c9d983f18fc0a9d812bc22', commit_message='Upload tokenizer', commit_description='', oid='038a864771e9afe4c0c9d983f18fc0a9d812bc22', pr_url=None, repo_url=RepoUrl('https://huggingface.co/Mozilla/mobilebert-uncased-finetuned-LoRA-intent-classifier', endpoint='https://huggingface.co', repo_type='model', repo_id='Mozilla/mobilebert-uncased-finetuned-LoRA-intent-classifier'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_model_dir = \"tmp/mobilebert_lora_combined_model\"\n",
    "merged_repo_id = \"Mozilla/mobilebert-uncased-finetuned-LoRA-intent-classifier\"  \n",
    "\n",
    "merged_model.push_to_hub(merged_repo_id)\n",
    "tokenizer.push_to_hub(merged_repo_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b1bcba70-77f1-493e-8c35-e135ec2f9893",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428ce05e-44be-4fc1-b8bb-ada9f1415386",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "my_env",
   "name": ".m124",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/:m124"
  },
  "kernelspec": {
   "display_name": "Python (my_env) (Local)",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
