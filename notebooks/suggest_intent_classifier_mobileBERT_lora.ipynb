{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83df52ac-a343-49ec-83bc-16b8c91b9dd0",
   "metadata": {},
   "source": [
    "Purpose of this notebook is to use LORA (aka Low Rank Adaptation method) and finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86420020-5a69-4a3b-a6be-6ce274be8bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m pip install -q datasets peft evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54679b61-b9f8-4a5c-a846-0f11a1946d49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !python -m pip uninstall -y pyarrow datasets ibis-framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59bd4be8-9789-447d-880a-264763f117fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !python -m pip install pyarrow>=15.0.0 datasets peft evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e05e4a8e-313a-48e5-9cb6-16ec108133bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !python -m pip show pyarrow datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28a5ba79-b2c6-4ab7-b0dd-940eeab27cca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !python -m pip install pyarrow>=15.0.0 datasets peft evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96c683dd-30bd-448a-ada9-bc4562b61663",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/new_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "\n",
    "from transformers import (AutoTokenizer,\n",
    "                         AutoConfig,\n",
    "                         AutoModelForSequenceClassification,\n",
    "                         DataCollatorWithPadding,\n",
    "                         TrainingArguments,\n",
    "                         Trainer)\n",
    "\n",
    "from peft import PeftModel, PeftConfig, get_peft_model, LoraConfig\n",
    "import evaluate\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f32ae2ac-7f08-4fc4-baa7-10a7ccbcf800",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'mps'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e512cf-4776-4278-9612-ec5c8be44f80",
   "metadata": {},
   "source": [
    "#### Base Model (mobileBERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1dc1475-55e2-42ca-a881-8f33e475f41c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MobileBertForSequenceClassification were not initialized from the model checkpoint at google/mobilebert-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint = 'google/mobilebert-uncased'\n",
    "id2label = {0: 'information_intent',\n",
    "            1: 'yelp_intent',\n",
    "            2: 'navigation_intent',\n",
    "            3: 'travel_intent',\n",
    "            4: 'purchase_intent',\n",
    "            5: 'weather_intent',\n",
    "            6: 'translation_intent',\n",
    "            7: 'unknown'}\n",
    "label2id = {label:id for id,label in id2label.items()}\n",
    "\n",
    "\n",
    "# generate classification model from model chckpoints\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    num_labels=8,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57a893d3-2bf9-45cb-b678-436748405b94",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileBertForSequenceClassification(\n",
       "  (mobilebert): MobileBertModel(\n",
       "    (embeddings): MobileBertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 128, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 512)\n",
       "      (token_type_embeddings): Embedding(2, 512)\n",
       "      (embedding_transformation): Linear(in_features=384, out_features=512, bias=True)\n",
       "      (LayerNorm): NoNorm()\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (encoder): MobileBertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-23): 24 x MobileBertLayer(\n",
       "          (attention): MobileBertAttention(\n",
       "            (self): MobileBertSelfAttention(\n",
       "              (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): MobileBertSelfOutput(\n",
       "              (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): MobileBertIntermediate(\n",
       "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (intermediate_act_fn): ReLU()\n",
       "          )\n",
       "          (output): MobileBertOutput(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "            (bottleneck): OutputBottleneck(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (bottleneck): Bottleneck(\n",
       "            (input): BottleneckLayer(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "            (attention): BottleneckLayer(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "          (ffn): ModuleList(\n",
       "            (0-2): 3 x FFNLayer(\n",
       "              (intermediate): MobileBertIntermediate(\n",
       "                (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "                (intermediate_act_fn): ReLU()\n",
       "              )\n",
       "              (output): FFNOutput(\n",
       "                (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "                (LayerNorm): NoNorm()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): MobileBertPooler()\n",
       "  )\n",
       "  (dropout): Dropout(p=0.0, inplace=False)\n",
       "  (classifier): Linear(in_features=512, out_features=8, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbeaa99b-10c2-44ed-8d21-08ed2b3990bd",
   "metadata": {},
   "source": [
    "#### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81eb7dac-565f-4247-b42d-fe2d7675ec60",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138187\n",
      "target\n",
      "information_intent    114367\n",
      "weather_intent         13196\n",
      "yelp_intent             8247\n",
      "navigation_intent       1361\n",
      "purchase_intent          519\n",
      "travel_intent            320\n",
      "translation_intent       162\n",
      "unknown                   15\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what is chocolate considered</td>\n",
       "      <td>information_intent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>which of the following statements is consisten...</td>\n",
       "      <td>information_intent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>average salary electrical engineer entry level</td>\n",
       "      <td>information_intent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>can you do a mail merge from excel</td>\n",
       "      <td>information_intent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>types computer operating system</td>\n",
       "      <td>information_intent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>what is the switchgear</td>\n",
       "      <td>information_intent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>what does a taipan snake look like</td>\n",
       "      <td>information_intent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>what is a wifi extender</td>\n",
       "      <td>information_intent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>individual supply economics definition</td>\n",
       "      <td>information_intent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>when does halloween town start</td>\n",
       "      <td>information_intent</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sequence              target\n",
       "0                       what is chocolate considered  information_intent\n",
       "1  which of the following statements is consisten...  information_intent\n",
       "2     average salary electrical engineer entry level  information_intent\n",
       "3                 can you do a mail merge from excel  information_intent\n",
       "4                    types computer operating system  information_intent\n",
       "5                             what is the switchgear  information_intent\n",
       "6                 what does a taipan snake look like  information_intent\n",
       "7                            what is a wifi extender  information_intent\n",
       "8             individual supply economics definition  information_intent\n",
       "9                     when does halloween town start  information_intent"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/marco_train.csv\")\n",
    "print(len(df))\n",
    "print(df['target'].value_counts())\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb24484d-7380-49b6-b67f-5b645e46cf49",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    138187.000000\n",
      "mean         28.606085\n",
      "std          10.290872\n",
      "min           6.000000\n",
      "10%          17.000000\n",
      "20%          20.000000\n",
      "25%          22.000000\n",
      "30%          23.000000\n",
      "40%          25.000000\n",
      "50%          27.000000\n",
      "60%          30.000000\n",
      "70%          32.000000\n",
      "75%          34.000000\n",
      "80%          36.000000\n",
      "90%          41.000000\n",
      "95%          45.000000\n",
      "98%          53.000000\n",
      "99%          60.000000\n",
      "99.5%        69.000000\n",
      "99.8%        85.000000\n",
      "99.9%        98.814000\n",
      "max         193.000000\n",
      "Name: sequence, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(df['sequence'].apply(len).describe(percentiles=[.1, .2, .25, .3, .4, .5, .6, .7, .75, .8, .9, .95, .98, .99, .995, .998, .999]))\n",
    "df['sequence'].apply(len).hist(bins=25);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "082fb996-037b-4353-8739-7047d6142f69",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>which of the following statements is consistent with the second law of thermodynamics?</td>\n",
       "      <td>information_intent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>secure the blessings of liberty to ourselves and our posterity meaning</td>\n",
       "      <td>information_intent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>carbon dioxide is released during which stage of cellular respiration</td>\n",
       "      <td>information_intent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>which statement is an example of an effective claim for an argumentative essay?</td>\n",
       "      <td>information_intent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>when light is absorbed by chlorophyll molecules, they lose their electrons, which are immediatel...</td>\n",
       "      <td>information_intent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127703</th>\n",
       "      <td>what are the requirements to obtain an emergency us passport renewal</td>\n",
       "      <td>information_intent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127760</th>\n",
       "      <td>which kingdom is made up of organisms that can be unicellular or multicellular</td>\n",
       "      <td>information_intent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128017</th>\n",
       "      <td>what type of reaction breaks the bonds that join the phosphate groups in an atp molecule</td>\n",
       "      <td>information_intent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128030</th>\n",
       "      <td>the region of the globe where the gulf stream and other warm water currents originate is known a...</td>\n",
       "      <td>information_intent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128056</th>\n",
       "      <td>c++ cannot determine which instance of function template std::count is intended</td>\n",
       "      <td>information_intent</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>969 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                   sequence  \\\n",
       "1                    which of the following statements is consistent with the second law of thermodynamics?   \n",
       "232                                  secure the blessings of liberty to ourselves and our posterity meaning   \n",
       "347                                   carbon dioxide is released during which stage of cellular respiration   \n",
       "497                         which statement is an example of an effective claim for an argumentative essay?   \n",
       "639     when light is absorbed by chlorophyll molecules, they lose their electrons, which are immediatel...   \n",
       "...                                                                                                     ...   \n",
       "127703                                 what are the requirements to obtain an emergency us passport renewal   \n",
       "127760                       which kingdom is made up of organisms that can be unicellular or multicellular   \n",
       "128017             what type of reaction breaks the bonds that join the phosphate groups in an atp molecule   \n",
       "128030  the region of the globe where the gulf stream and other warm water currents originate is known a...   \n",
       "128056                      c++ cannot determine which instance of function template std::count is intended   \n",
       "\n",
       "                    target  \n",
       "1       information_intent  \n",
       "232     information_intent  \n",
       "347     information_intent  \n",
       "497     information_intent  \n",
       "639     information_intent  \n",
       "...                    ...  \n",
       "127703  information_intent  \n",
       "127760  information_intent  \n",
       "128017  information_intent  \n",
       "128030  information_intent  \n",
       "128056  information_intent  \n",
       "\n",
       "[969 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 100)\n",
    "df.loc[df['sequence'].apply(lambda text: len(text) > 64)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7e0d5f3-b927-477e-ac5b-5e05fce4835b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/new_env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                      sequence  \\\n",
      "0                                                                 what is chocolate considered   \n",
      "1       which of the following statements is consistent with the second law of thermodynamics?   \n",
      "2                                               average salary electrical engineer entry level   \n",
      "3                                                           can you do a mail merge from excel   \n",
      "4                                                              types computer operating system   \n",
      "...                                                                                        ...   \n",
      "138182                                                      What is the weaher in Cedar Rapids   \n",
      "138183                                                       What is the weathr in Sioux Falls   \n",
      "138184                                                                  the wather in syracuse   \n",
      "138185                                                           What is the weaher in Ottumwa   \n",
      "138186                                                     What is the weaher in Rochester, NY   \n",
      "\n",
      "        token_length  \n",
      "0                  6  \n",
      "1                 20  \n",
      "2                  8  \n",
      "3                 10  \n",
      "4                  6  \n",
      "...              ...  \n",
      "138182            11  \n",
      "138183            11  \n",
      "138184             7  \n",
      "138185            12  \n",
      "138186            12  \n",
      "\n",
      "[138187 rows x 2 columns]\n",
      "Max token length: 55\n",
      "Average token length: 8.04277536960785\n",
      "90th percentile token length: 11.0\n",
      "95th percentile token length: 12.0\n",
      "98th percentile token length: 13.0\n",
      "99th percentile token length: 15.0\n",
      "99.5th percentile token length: 16.0\n",
      "99.9th percentile token length: 23.0\n"
     ]
    }
   ],
   "source": [
    "# create tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, add_prefix_space=True)\n",
    "\n",
    "token_lengths = []\n",
    "for sequence in df['sequence'].values:\n",
    "    tokens = tokenizer(sequence, truncation=False)['input_ids']  # Get tokenized input IDs\n",
    "    token_lengths.append(len(tokens))\n",
    "\n",
    "# Create a DataFrame for analysis\n",
    "temp_df = pd.DataFrame({'sequence': df['sequence'].values, 'token_length': token_lengths})\n",
    "\n",
    "# Display token lengths\n",
    "print(temp_df)\n",
    "\n",
    "# Optional: Analyze token lengths for deciding the best max_length\n",
    "print(f\"Max token length: {temp_df['token_length'].max()}\")\n",
    "print(f\"Average token length: {temp_df['token_length'].mean()}\")\n",
    "print(f\"90th percentile token length: {temp_df['token_length'].quantile(0.9)}\")\n",
    "print(f\"95th percentile token length: {temp_df['token_length'].quantile(0.95)}\")\n",
    "print(f\"98th percentile token length: {temp_df['token_length'].quantile(0.98)}\")\n",
    "print(f\"99th percentile token length: {temp_df['token_length'].quantile(0.99)}\")\n",
    "print(f\"99.5th percentile token length: {temp_df['token_length'].quantile(0.995)}\")\n",
    "print(f\"99.9th percentile token length: {temp_df['token_length'].quantile(0.999)}\")\n",
    "\n",
    "del temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13e6c934-fdc6-4d28-9c87-69eec74e5beb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    17155\n",
      "5    13196\n",
      "1     8247\n",
      "2     1361\n",
      "4      519\n",
      "3      320\n",
      "6      162\n",
      "7       15\n",
      "Name: count, dtype: int64\n",
      "Size of sampled_df = 40975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_9692/5394313.py:15: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sampled_df = df.groupby('target', group_keys=False).apply(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>target</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what county is forsyth, mo</td>\n",
       "      <td>information_intent</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>how to get command block</td>\n",
       "      <td>information_intent</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what is a falafel</td>\n",
       "      <td>information_intent</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>how to put an hp ink cartridge in</td>\n",
       "      <td>information_intent</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>definition of fur trade</td>\n",
       "      <td>information_intent</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            sequence              target  label\n",
       "0         what county is forsyth, mo  information_intent      0\n",
       "1           how to get command block  information_intent      0\n",
       "2                  what is a falafel  information_intent      0\n",
       "3  how to put an hp ink cartridge in  information_intent      0\n",
       "4            definition of fur trade  information_intent      0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select only a sample from the actual data\n",
    "\n",
    "sampling_percentages = {\n",
    "    'information_intent': 0.15,  # 15% sampling for information_intent\n",
    "    'yelp_intent': 1.0,          # 100% sampling for yelp_intent\n",
    "    'weather_intent': 1.0,       # 100% sampling for weather_intent\n",
    "    'navigation_intent': 1.0,    # 100% sampling for navigation_intent\n",
    "    'purchase_intent': 1.0,      # 100% sampling for purchase_intent\n",
    "    'translation_intent': 1.0,   # 100% sampling for translation_intent\n",
    "    'travel_intent': 1.0,        # 100% sampling for travel_intent\n",
    "    'unknown': 1.0               # 100% sampling for unknown\n",
    "}\n",
    "\n",
    "# Sample from each target group based on the defined percentages\n",
    "sampled_df = df.groupby('target', group_keys=False).apply(\n",
    "    lambda x: x.sample(frac=sampling_percentages.get(x.name, 1.0))\n",
    ").reset_index(drop=True)\n",
    "\n",
    "sampled_df['label'] = sampled_df['target'].map(label2id)\n",
    "# sampled_df = sampled_df.rename(columns={'target': 'label'})\n",
    "\n",
    "print(sampled_df['label'].value_counts())\n",
    "print(f\"Size of sampled_df = {len(sampled_df)}\")\n",
    "sampled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8dadb9a2-6184-4e50-bf21-8063e31edbb1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['sequence', 'target', 'label'],\n",
      "        num_rows: 38926\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['sequence', 'target', 'label'],\n",
      "        num_rows: 2049\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Split the DataFrame into train and validation sets\n",
    "train_df, val_df = train_test_split(sampled_df, test_size=0.05, random_state=42, stratify=sampled_df['label'])\n",
    "\n",
    "# Step 2: Convert Pandas DataFrames to Hugging Face Datasets\n",
    "train_dataset = Dataset.from_pandas(train_df, preserve_index=False)\n",
    "val_dataset = Dataset.from_pandas(val_df, preserve_index=False)\n",
    "\n",
    "# Step 3: Create a DatasetDict\n",
    "dataset_dict = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'validation': val_dataset\n",
    "})\n",
    "\n",
    "# Step 4: Verify the structure of DatasetDict\n",
    "print(dataset_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0613b1e7-e4ec-4b18-91a2-2648c42a91b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    16297\n",
       "5    12536\n",
       "1     7835\n",
       "2     1293\n",
       "4      493\n",
       "3      304\n",
       "6      154\n",
       "7       14\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68d476d6-4aa2-4180-889b-49f8e5251219",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    858\n",
       "5    660\n",
       "1    412\n",
       "2     68\n",
       "4     26\n",
       "3     16\n",
       "6      8\n",
       "7      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ae60f7-3f28-4d95-bee7-28d05b68566f",
   "metadata": {},
   "source": [
    "#### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17cb2d99-4f2f-4caa-8f1f-747fbc9c9082",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# add pad token if none exists\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# tokenize function\n",
    "def tokenize_function(examples):\n",
    "    # extract text\n",
    "    text = examples[\"sequence\"]\n",
    "\n",
    "    # tokenize and truncate text\n",
    "    tokenizer.truncation_side = \"right\"\n",
    "    tokenized_inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        padding=True,  # Pad the sequences to the longest in the batch\n",
    "        max_length=64\n",
    "    )\n",
    "    return tokenized_inputs\n",
    "\n",
    "# def fix_labels(examples):\n",
    "#     examples[\"idx\"] = int(examples[\"idx\"])\n",
    "#     return examples\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d52d8863-7705-40d2-a6b4-26b1865f5c1c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 38926/38926 [00:01<00:00, 22507.27 examples/s]\n",
      "Map: 100%|██████████| 2049/2049 [00:00<00:00, 7663.40 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sequence', 'target', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 38926\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sequence', 'target', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 2049\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset = dataset_dict.map(tokenize_function, batched=True)\n",
    "# tokenized_dataset = tokenized_dataset.map(fix_labels)\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56166c5b-958c-4921-961a-7e42c1ef37d7",
   "metadata": {},
   "source": [
    "#### Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d481d862-dfe6-4635-9d0c-7c827a2155f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    logits, labels = p\n",
    "    predictions = np.argmax(logits, axis=1)\n",
    "    # Combine metrics\n",
    "    accuracy_metric = evaluate.load(\"accuracy\")\n",
    "    precision_metric = evaluate.load(\"precision\")\n",
    "    recall_metric = evaluate.load(\"recall\")\n",
    "    f1_metric = evaluate.load(\"f1\")\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_metric.compute(predictions=predictions, references=labels)\n",
    "    precision = precision_metric.compute(predictions=predictions, references=labels, average=\"weighted\")\n",
    "    recall = recall_metric.compute(predictions=predictions, references=labels, average=\"weighted\")\n",
    "    f1 = f1_metric.compute(predictions=predictions, references=labels, average=\"weighted\")\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy[\"accuracy\"],\n",
    "        \"precision\": precision[\"precision\"],\n",
    "        \"recall\": recall[\"recall\"],\n",
    "        \"f1\": f1[\"f1\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f08d8464-0714-4021-a266-9ceb64f36f0b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untrained model predictions:\n",
      "----------------------------\n",
      "floor repair cost -> translation_intent\n",
      "denture fix -> translation_intent\n",
      "who is the us president -> translation_intent\n",
      "italian food -> translation_intent\n",
      "sandwiches in seattle -> translation_intent\n",
      "seattle weather -> translation_intent\n",
      "weather seattle -> translation_intent\n",
      "boston wether -> translation_intent\n",
      "Boston wether -> translation_intent\n",
      "weather boston -> translation_intent\n",
      "weather Boston -> translation_intent\n",
      "Weather Boston -> translation_intent\n",
      "weathr boston -> translation_intent\n",
      "seattle weathr -> translation_intent\n"
     ]
    }
   ],
   "source": [
    "### Evaluate untrained model\n",
    "\n",
    "text_list = [\n",
    "    'floor repair cost',\n",
    "    'denture fix',\n",
    "    'who is the us president',\n",
    "    'italian food',\n",
    "    'sandwiches in seattle',\n",
    "    'seattle weather',\n",
    "    'weather seattle',\n",
    "    'boston wether',\n",
    "    'Boston wether',\n",
    "    'weather boston',\n",
    "    'weather Boston',\n",
    "    'Weather Boston',\n",
    "    'weathr boston',\n",
    "    'seattle weathr',\n",
    "]\n",
    "\n",
    "sample_labels = [\n",
    "    label2id[\"yelp_intent\"],\n",
    "    label2id[\"yelp_intent\"],\n",
    "    label2id[\"information_intent\"],\n",
    "    label2id[\"yelp_intent\"],\n",
    "    label2id[\"yelp_intent\"]\n",
    "]\n",
    "\n",
    "print(\"Untrained model predictions:\")\n",
    "print(\"----------------------------\")\n",
    "predictions = []\n",
    "logits_list = []\n",
    "for text in text_list:\n",
    "    inputs = tokenizer.encode(text, return_tensors=\"pt\")\n",
    "    logits = model(inputs).logits\n",
    "    prediction = torch.argmax(logits, dim=1).item()\n",
    "    predictions.append(prediction)\n",
    "    print(text + \" -> \" + id2label[prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "735012ed-4d2c-4800-815c-7bd7238524ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# compute_metrics((logits_list, sample_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bfb5ad-391d-42da-bcf5-d62e39642225",
   "metadata": {},
   "source": [
    "#### Model finetuning with LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cece8cd8-b017-4f80-9d9a-713041270fc2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 28,680 || all params: 24,614,672 || trainable%: 0.1165\n"
     ]
    }
   ],
   "source": [
    "peft_config = LoraConfig(task_type=\"SEQ_CLS\",\n",
    "                         r=4, # intrinsic rank of trainable weight matrix\n",
    "                         lora_alpha=32, # similar to learning_rate\n",
    "                         lora_dropout=0.01, # probability of dropout nodes\n",
    "                         target_modules=['attention.self.query']) # LoRA is applied to query layer\n",
    "\n",
    "# 'attention.self.key', 'attention.self.value'\n",
    "\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "93c9ac1c-cd57-4173-b208-78831d9c4f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name, module in model.named_modules():\n",
    "#     print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ccdcde-6b2c-499d-a185-d04dbd1b6ba7",
   "metadata": {},
   "source": [
    "#### Define hyper parameters and training arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "84297802-ae8a-4fef-882a-7d7145de72bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-3\n",
    "batch_size = 16\n",
    "num_epochs = 10\n",
    "\n",
    "# training args\n",
    "training_args = TrainingArguments(\n",
    "    # output_dir=model_checkpoint + \"-lora-intent-classification-v3\",\n",
    "    output_dir=\"mobilebert-uncased\" + \"-lora-intent-classification-v3\",\n",
    "    learning_rate=lr,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=num_epochs,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "39930440-66ab-49a4-a198-04d03bb576ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data_collator.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "615cdb83-edc7-409a-a929-6c370c8aa9e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model, \n",
    "    args=training_args, # Hyperparamaters\n",
    "    train_dataset=tokenized_dataset[\"train\"], # training data\n",
    "    eval_dataset=tokenized_dataset[\"validation\"], # validation data\n",
    "    tokenizer=tokenizer, # tokenizer\n",
    "    data_collator=data_collator, # dynamic sequence padding\n",
    "    compute_metrics=compute_metrics,  # model perfomance evaluation metric\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f9fde457-1a0d-4552-b6fa-1c0642349972",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24330' max='24330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24330/24330 43:04, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>372.125900</td>\n",
       "      <td>3.547696</td>\n",
       "      <td>0.903367</td>\n",
       "      <td>0.903586</td>\n",
       "      <td>0.903367</td>\n",
       "      <td>0.901405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>597.434600</td>\n",
       "      <td>6.268109</td>\n",
       "      <td>0.904344</td>\n",
       "      <td>0.911594</td>\n",
       "      <td>0.904344</td>\n",
       "      <td>0.903839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>291.135200</td>\n",
       "      <td>0.246130</td>\n",
       "      <td>0.931674</td>\n",
       "      <td>0.933125</td>\n",
       "      <td>0.931674</td>\n",
       "      <td>0.930621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>216.410600</td>\n",
       "      <td>13.672197</td>\n",
       "      <td>0.935090</td>\n",
       "      <td>0.935512</td>\n",
       "      <td>0.935090</td>\n",
       "      <td>0.933506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>244.169500</td>\n",
       "      <td>0.457011</td>\n",
       "      <td>0.938507</td>\n",
       "      <td>0.938730</td>\n",
       "      <td>0.938507</td>\n",
       "      <td>0.937107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>178.902700</td>\n",
       "      <td>0.380596</td>\n",
       "      <td>0.943875</td>\n",
       "      <td>0.943950</td>\n",
       "      <td>0.943875</td>\n",
       "      <td>0.942585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>88.390200</td>\n",
       "      <td>0.168334</td>\n",
       "      <td>0.955588</td>\n",
       "      <td>0.955377</td>\n",
       "      <td>0.955588</td>\n",
       "      <td>0.955343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>255.284600</td>\n",
       "      <td>0.158661</td>\n",
       "      <td>0.955588</td>\n",
       "      <td>0.954973</td>\n",
       "      <td>0.955588</td>\n",
       "      <td>0.954921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>36.402800</td>\n",
       "      <td>0.142108</td>\n",
       "      <td>0.959980</td>\n",
       "      <td>0.959569</td>\n",
       "      <td>0.959980</td>\n",
       "      <td>0.959536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>6.477400</td>\n",
       "      <td>0.139003</td>\n",
       "      <td>0.963885</td>\n",
       "      <td>0.963437</td>\n",
       "      <td>0.963885</td>\n",
       "      <td>0.963456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/new_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jupyter/new_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jupyter/new_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jupyter/new_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jupyter/new_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jupyter/new_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jupyter/new_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jupyter/new_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jupyter/new_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jupyter/new_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=24330, training_loss=3760.1492261856024, metrics={'train_runtime': 2585.0785, 'train_samples_per_second': 150.58, 'train_steps_per_second': 9.412, 'total_flos': 1916873502192000.0, 'train_loss': 3760.1492261856024, 'epoch': 10.0})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1da3c5f1-ef7f-4ca1-9792-4879b621f267",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): MobileBertForSequenceClassification(\n",
       "      (mobilebert): MobileBertModel(\n",
       "        (embeddings): MobileBertEmbeddings(\n",
       "          (word_embeddings): Embedding(30522, 128, padding_idx=0)\n",
       "          (position_embeddings): Embedding(512, 512)\n",
       "          (token_type_embeddings): Embedding(2, 512)\n",
       "          (embedding_transformation): Linear(in_features=384, out_features=512, bias=True)\n",
       "          (LayerNorm): NoNorm()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (encoder): MobileBertEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-23): 24 x MobileBertLayer(\n",
       "              (attention): MobileBertAttention(\n",
       "                (self): MobileBertSelfAttention(\n",
       "                  (query): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=128, out_features=128, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.01, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=128, out_features=4, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=4, out_features=128, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "                  (value): Linear(in_features=512, out_features=128, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): MobileBertSelfOutput(\n",
       "                  (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "                  (LayerNorm): NoNorm()\n",
       "                )\n",
       "              )\n",
       "              (intermediate): MobileBertIntermediate(\n",
       "                (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "                (intermediate_act_fn): ReLU()\n",
       "              )\n",
       "              (output): MobileBertOutput(\n",
       "                (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "                (LayerNorm): NoNorm()\n",
       "                (bottleneck): OutputBottleneck(\n",
       "                  (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "                  (LayerNorm): NoNorm()\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (bottleneck): Bottleneck(\n",
       "                (input): BottleneckLayer(\n",
       "                  (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "                  (LayerNorm): NoNorm()\n",
       "                )\n",
       "                (attention): BottleneckLayer(\n",
       "                  (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "                  (LayerNorm): NoNorm()\n",
       "                )\n",
       "              )\n",
       "              (ffn): ModuleList(\n",
       "                (0-2): 3 x FFNLayer(\n",
       "                  (intermediate): MobileBertIntermediate(\n",
       "                    (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "                    (intermediate_act_fn): ReLU()\n",
       "                  )\n",
       "                  (output): FFNOutput(\n",
       "                    (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "                    (LayerNorm): NoNorm()\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (pooler): MobileBertPooler()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (classifier): ModulesToSaveWrapper(\n",
       "        (original_module): Linear(in_features=512, out_features=8, bias=True)\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): Linear(in_features=512, out_features=8, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "15d874c9-e652-4c17-8a54-11d94710debb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "floor repair cost -> yelp_intent\n",
      "denture fix -> yelp_intent\n",
      "who is the us president -> information_intent\n",
      "italian food -> yelp_intent\n",
      "sandwiches in seattle -> yelp_intent\n",
      "seattle weather -> weather_intent\n",
      "weather seattle -> weather_intent\n",
      "boston wether -> weather_intent\n",
      "Boston wether -> weather_intent\n",
      "weather boston -> weather_intent\n",
      "weather Boston -> weather_intent\n",
      "Weather Boston -> weather_intent\n",
      "weathr boston -> weather_intent\n",
      "seattle weathr -> weather_intent\n"
     ]
    }
   ],
   "source": [
    "trainer.model.eval()\n",
    "with torch.no_grad():\n",
    "    for text in text_list:\n",
    "        inputs = tokenizer.encode(text, return_tensors=\"pt\").to(device)\n",
    "        logits = trainer.model(inputs).logits\n",
    "        prediction = torch.argmax(logits, dim=1).item()\n",
    "        print(text + \" -> \" + id2label[prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "66aae059-b207-43d5-8a78-a76901550c8a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1.4M\n",
      "-rw-r--r-- 1 jupyter jupyter 5.0K Oct  9 12:21 README.md\n",
      "-rw-r--r-- 1 jupyter jupyter  679 Oct  9 12:21 adapter_config.json\n",
      "-rw-r--r-- 1 jupyter jupyter 119K Oct  9 12:21 adapter_model.safetensors\n",
      "-rw-r--r-- 1 jupyter jupyter 266K Oct  9 12:21 optimizer.pt\n",
      "-rw-r--r-- 1 jupyter jupyter  14K Oct  9 12:21 rng_state.pth\n",
      "-rw-r--r-- 1 jupyter jupyter 1.1K Oct  9 12:21 scheduler.pt\n",
      "-rw-r--r-- 1 jupyter jupyter  125 Oct  9 12:21 special_tokens_map.json\n",
      "-rw-r--r-- 1 jupyter jupyter 695K Oct  9 12:21 tokenizer.json\n",
      "-rw-r--r-- 1 jupyter jupyter 1.3K Oct  9 12:21 tokenizer_config.json\n",
      "-rw-r--r-- 1 jupyter jupyter  13K Oct  9 12:21 trainer_state.json\n",
      "-rw-r--r-- 1 jupyter jupyter 5.2K Oct  9 12:21 training_args.bin\n",
      "-rw-r--r-- 1 jupyter jupyter 227K Oct  9 12:21 vocab.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "# !ls -ltr distilbert-base-uncased-lora-intent-classification/checkpoint-15048\n",
    "# !ls -lh distilbert-base-uncased-lora-intent-classification-v2/checkpoint-67716\n",
    "# !ls -lh distilbert-base-uncased-lora-intent-classification-v2/checkpoint-24330\n",
    "!ls -lh mobilebert-uncased-lora-intent-classification-v3/checkpoint-24330"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6557a796-1ba4-455d-9c72-acb52f8958c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !ls -lh \"distilbert-base-uncased-lora-intent-classification/checkpoint-15048/adapter_model.safetensors\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "34a5d900-a6f7-446c-b608-3beb4104b850",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !python -m pip install onnx onnxruntime optimum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c08157f-ff0c-46a3-aa0d-f04493a71d36",
   "metadata": {},
   "source": [
    "#### Load the LoRA model from checkpoint after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "041cee58-787b-430c-a9c4-c4aadcf87a58",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MobileBertForSequenceClassification were not initialized from the model checkpoint at google/mobilebert-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  0.6429,   5.4794,   0.1232,  -7.0743,  -5.3529,  -8.9513, -10.5316,\n",
      "          -8.4416]], grad_fn=<AddmmBackward0>)\n",
      "1 yelp_intent\n",
      "tensor([[0., 1., 0., 0., 0., 0., 0., 0.]], grad_fn=<RoundBackward0>)\n"
     ]
    }
   ],
   "source": [
    "id2label = {0: 'information_intent',\n",
    "            1: 'yelp_intent',\n",
    "            2: 'navigation_intent',\n",
    "            3: 'travel_intent',\n",
    "            4: 'purchase_intent',\n",
    "            5: 'weather_intent',\n",
    "            6: 'translation_intent',\n",
    "            7: 'unknown'}\n",
    "label2id = {label:id for id,label in id2label.items()}\n",
    "\n",
    "\n",
    "# output_dir=\"distilbert-base-uncased-lora-intent-classification/checkpoint-37620\"\n",
    "# output_dir = \"distilbert-base-uncased-lora-intent-classification-v2/checkpoint-67716\"\n",
    "# output_dir = \"distilbert-base-uncased-lora-intent-classification-v2/checkpoint-97320\"\n",
    "output_dir = \"mobilebert-uncased-lora-intent-classification-v3/checkpoint-24330\"\n",
    "\n",
    "# Load the tokenizer (from the output directory)\n",
    "tokenizer = AutoTokenizer.from_pretrained(output_dir, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=64)\n",
    "\n",
    "# Load the base model from the original checkpoint (base pre-trained model)\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained('google/mobilebert-uncased', num_labels=8, id2label=id2label, label2id=label2id)\n",
    "\n",
    "# Load the LoRA configuration and model\n",
    "peft_config = PeftConfig.from_pretrained(output_dir)\n",
    "lora_model = PeftModel.from_pretrained(base_model, output_dir)\n",
    "\n",
    "# Step 3: Save the combined model to a directory\n",
    "save_directory = \"tmp/mobilebert_lora_combined_model/\"\n",
    "lora_model.save_pretrained(save_directory)  # Save base model + LoRA weights\n",
    "\n",
    "# Now the `lora_model` contains both the base model and the LoRA weights.\n",
    "lora_model.eval()\n",
    "\n",
    "# Example inference\n",
    "inputs = tokenizer([\"looking for home cleaning \"], return_tensors=\"pt\")\n",
    "outputs = lora_model(**inputs)\n",
    "logits = outputs.logits\n",
    "print(logits)\n",
    "\n",
    "\n",
    "prediction = torch.argmax(logits, dim=1).item()\n",
    "print(prediction, id2label[prediction])\n",
    "probabilities = torch.softmax(logits, dim=1)\n",
    "rounded_probabilities = torch.round(probabilities)\n",
    "print(rounded_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "24da08c5-07d3-4905-b806-e260a1db3d4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from optimum.onnxruntime import ORTModelForSequenceClassification\n",
    "\n",
    "\n",
    "\n",
    "# ort_model = ORTModelForSequenceClassification.from_pretrained(\n",
    "#     save_directory, \n",
    "#     export=True, \n",
    "#     provider=\"CPUExecutionProvider\",  # Ensure you're specifying the execution provider (e.g., CPU)\n",
    "#     library=\"transformers\"  # Explicitly set the model library to transformers\n",
    "# )\n",
    "\n",
    "# # Save the ONNX model and tokenizer\n",
    "# ort_model.save_pretrained(\"tmp/onnx/\")\n",
    "# tokenizer = AutoTokenizer.from_pretrained(output_dir)\n",
    "# tokenizer.save_pretrained(save_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9e3d928b-cfc2-464b-a407-467936b079a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # !python -m optimum.exporters.onnx --model distilbert-base-uncased-lora-intent-classification/checkpoint-37620 --library transformers --task text-classification --output tmp/onnx/\n",
    "# !python -m optimum.exporters.onnx \\\n",
    "#     --model distilbert-base-uncased-lora-intent-classification-v2/checkpoint-67716 \\\n",
    "#     --task text-classification \\\n",
    "#     --library-name transformers \\\n",
    "#     tmp/onnx/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d5f259a5-9032-4614-b0fc-b6c685ea250e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MobileBertForSequenceClassification were not initialized from the model checkpoint at google/mobilebert-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('tmp/mobilebert_lora_combined_model/tokenizer_config.json',\n",
       " 'tmp/mobilebert_lora_combined_model/special_tokens_map.json',\n",
       " 'tmp/mobilebert_lora_combined_model/vocab.txt',\n",
       " 'tmp/mobilebert_lora_combined_model/added_tokens.json',\n",
       " 'tmp/mobilebert_lora_combined_model/tokenizer.json')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "# Step 1: Load the base model (DistilBERT)\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained('google/mobilebert-uncased', num_labels=8, id2label=id2label, label2id=label2id)\n",
    "\n",
    "# Step 2: Load the LoRA adapter weights\n",
    "# output_dir = \"distilbert-base-uncased-lora-intent-classification/checkpoint-37620\"\n",
    "# output_dir = \"distilbert-base-uncased-lora-intent-classification-v2/checkpoint-67716\"\n",
    "# output_dir = \"distilbert-base-uncased-lora-intent-classification-v2/checkpoint-97320\"\n",
    "output_dir = \"mobilebert-uncased-lora-intent-classification-v3/checkpoint-24330\"\n",
    "peft_config = PeftConfig.from_pretrained(output_dir)\n",
    "lora_model = PeftModel.from_pretrained(base_model, output_dir)\n",
    "\n",
    "# Step 3: Merge LoRA weights into the base model\n",
    "# After this, the model will have both base and LoRA weights applied\n",
    "merged_model = lora_model.merge_and_unload()\n",
    "\n",
    "# Step 4: Save the full model (base model + LoRA weights)\n",
    "save_directory = \"tmp/mobilebert_lora_combined_model/\"\n",
    "merged_model.save_pretrained(save_directory)\n",
    "tokenizer = AutoTokenizer.from_pretrained(output_dir)  # Load the tokenizer\n",
    "tokenizer.save_pretrained(save_directory)  # Save the tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7eb33ea5-05c4-4417-8c86-05782471d680",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !huggingface-cli whoami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "75982821-faaf-45ba-9936-26f1c275f78f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|██████████| 98.5M/98.5M [00:02<00:00, 33.8MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/Mozilla/mobilebert-uncased-finetuned-LoRA-intent-classifier/commit/ec7369530eeae780e29c13059084cceea6c06f2b', commit_message='Upload tokenizer', commit_description='', oid='ec7369530eeae780e29c13059084cceea6c06f2b', pr_url=None, repo_url=RepoUrl('https://huggingface.co/Mozilla/mobilebert-uncased-finetuned-LoRA-intent-classifier', endpoint='https://huggingface.co', repo_type='model', repo_id='Mozilla/mobilebert-uncased-finetuned-LoRA-intent-classifier'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_model_dir = \"tmp/lora_combined_model\"\n",
    "merged_repo_id = \"Mozilla/mobilebert-uncased-finetuned-LoRA-intent-classifier\"  \n",
    "\n",
    "merged_model.push_to_hub(merged_repo_id)\n",
    "tokenizer.push_to_hub(merged_repo_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b1bcba70-77f1-493e-8c35-e135ec2f9893",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428ce05e-44be-4fc1-b8bb-ada9f1415386",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "my_env",
   "name": ".m124",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/:m124"
  },
  "kernelspec": {
   "display_name": "Python (my_env) (Local)",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
