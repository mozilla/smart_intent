{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22bbbb75-8c65-440e-a059-c63c2fa91996",
   "metadata": {},
   "source": [
    "purpose of this notebook is to finetune the \"dslim/bert-base-NER\" model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7436463-26a4-4ebb-abd1-771ee134220b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/new_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "from transformers import TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6740344d-7d09-457a-bb68-a64f2b532103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'mps'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6093b56-0180-4b67-8b04-b562979979ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "full_dataset = Dataset.from_parquet(\"data/combined_ner_examples.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f06a123-bdd7-4655-ae16-92bdc655924f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'tokens', 'ner_tags'],\n",
       "    num_rows: 8127\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd3d3524-3a60-4ce2-863b-08a6dadd2fcc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Split the dataset into train and validation sets\n",
    "train_dataset = full_dataset.select(range(7127))  # Select first 6127 rows for training\n",
    "val_dataset = full_dataset.select(range(7127, 8127))  # Select last 1000 rows for validation\n",
    "\n",
    "# Combine them into a DatasetDict\n",
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'validation': val_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4ffc3cd-886d-4f7f-a8c8-8f5413628646",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags'],\n",
       "        num_rows: 7127\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "340175ec-d224-4c3b-aaa5-16037c61fff0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset['train'].to_pandas()['tokens'].apply(len).hist(bins=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2046667-d9ef-44ab-a444-dc95752478aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f20d0f6-fa8e-47d7-a60b-2e673e25685a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:00<00:00, 3937.31 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load the tokenizer for distilbert-based NER\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dslim/distilbert-NER\")\n",
    "\n",
    "# Function to tokenize the input and align labels with tokens\n",
    "def tokenize_and_align_labels(example):\n",
    "    # Tokenize 'tokens' while keeping track of word boundaries\n",
    "    tokenized_inputs = tokenizer(\n",
    "        example['tokens'], \n",
    "        is_split_into_words=True, \n",
    "        truncation=True, \n",
    "        padding='max_length',\n",
    "        max_length=64,\n",
    "    )\n",
    "    \n",
    "    # Get the word_ids (mapping from tokens to original words)\n",
    "    word_ids = tokenized_inputs.word_ids()\n",
    "    aligned_labels = []\n",
    "\n",
    "    previous_word_idx = None\n",
    "    for word_idx in word_ids:\n",
    "        if word_idx is None:\n",
    "            aligned_labels.append(-100)  # Special tokens ([CLS], [SEP], etc.)\n",
    "        elif word_idx != previous_word_idx:\n",
    "            aligned_labels.append(example['ner_tags'][word_idx])  # Assign the label to the first token of each word\n",
    "        else:\n",
    "            aligned_labels.append(-100)  # Subword tokens get label -100\n",
    "\n",
    "        previous_word_idx = word_idx\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = aligned_labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "# Apply the function to the dataset\n",
    "tokenized_dataset = dataset.map(tokenize_and_align_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "106935d0-9093-4ff9-8e0f-afe4aa2d792c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 7127\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "331d6dca-55d0-473e-94ca-90a152a9e9b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 7127,\n",
       " 'tokens': ['Jackson,',\n",
       "  'TN',\n",
       "  'is',\n",
       "  'home',\n",
       "  'to',\n",
       "  'several',\n",
       "  'tech',\n",
       "  'companies.'],\n",
       " 'ner_tags': [5, 6, 0, 0, 0, 0, 0, 0],\n",
       " 'input_ids': [101,\n",
       "  3160,\n",
       "  117,\n",
       "  157,\n",
       "  2249,\n",
       "  1110,\n",
       "  1313,\n",
       "  1106,\n",
       "  1317,\n",
       "  13395,\n",
       "  2557,\n",
       "  119,\n",
       "  102,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'labels': [-100,\n",
       "  5,\n",
       "  -100,\n",
       "  6,\n",
       "  -100,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset['validation'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1221fd4e-3f16-4ed4-9d9f-c359604545ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_predictions_and_labels(predictions, references):\n",
    "    true_predictions = []\n",
    "    true_labels = []\n",
    "    cmp_count = 0\n",
    "\n",
    "    for prediction, reference in zip(predictions, references):\n",
    "        # Only keep labels that are not -100\n",
    "        true_labels_example = [label for label in reference if label != -100]\n",
    "        \n",
    "        # Align predictions: Remove predictions for which the corresponding reference label is -100\n",
    "        true_predictions_example = [pred for pred, ref in zip(prediction, reference) if ref != -100]\n",
    "\n",
    "        # Ensure the length of predictions and labels matches\n",
    "        if len(true_predictions_example) == len(true_labels_example):\n",
    "            true_labels.append(true_labels_example)\n",
    "            true_predictions.append(true_predictions_example)\n",
    "            cmp_count += 1\n",
    "        else:\n",
    "            # Log or handle the error (example-level mismatch)\n",
    "            # print(f\"Skipping example due to mismatch: predictions ({len(true_predictions_example)}), labels ({len(true_labels_example)})\")\n",
    "            continue  # Skip this example\n",
    "\n",
    "    # Flatten the lists (convert from list of lists to a single list)\n",
    "    true_predictions = [pred for sublist in true_predictions for pred in sublist]\n",
    "    true_labels = [label for sublist in true_labels for label in sublist]\n",
    "    print(f\"cmp_count = {cmp_count} out of {len(predictions)}\")\n",
    "\n",
    "    return true_predictions, true_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f62dee2-077d-451f-af48-60eaf50e5edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    logits, labels = p\n",
    "    predictions = np.argmax(logits, axis=1)\n",
    "    \n",
    "    # Post-process the predictions and labels to remove -100 values\n",
    "    true_predictions, true_labels = postprocess_predictions_and_labels(predictions, labels)\n",
    "\n",
    "    # Combine metrics\n",
    "    accuracy_metric = evaluate.load(\"accuracy\")\n",
    "    precision_metric = evaluate.load(\"precision\")\n",
    "    recall_metric = evaluate.load(\"recall\")\n",
    "    f1_metric = evaluate.load(\"f1\")\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    precision = precision_metric.compute(predictions=true_predictions, references=true_labels, average=\"weighted\")\n",
    "    recall = recall_metric.compute(predictions=true_predictions, references=true_labels, average=\"weighted\")\n",
    "    f1 = f1_metric.compute(predictions=true_predictions, references=true_labels, average=\"weighted\")\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy[\"accuracy\"],\n",
    "        \"precision\": precision[\"precision\"],\n",
    "        \"recall\": recall[\"recall\"],\n",
    "        \"f1\": f1[\"f1\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f7acd16-763a-4055-b492-3007b5057da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load the pre-trained model\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"dslim/distilbert-NER\", num_labels=9)\n",
    "\n",
    "# Define the LoRA configuration\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.TOKEN_CLS,  # Task type is token classification (NER)\n",
    "    r=8,  # Low-rank dimension (you can experiment with this)\n",
    "    lora_alpha=32,  # Scaling factor for LoRA\n",
    "    lora_dropout=0.1,  # Dropout rate for LoRA\n",
    "    target_modules=['q_lin']  # LoRA is applied to query layer\n",
    ")\n",
    "\n",
    "# Apply LoRA to the model\n",
    "lora_model = get_peft_model(model, lora_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c185799-1fd7-4319-a2a5-89ba1ff52df1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/new_env/lib/python3.10/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2676' max='2676' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2676/2676 03:04, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.201609</td>\n",
       "      <td>0.088641</td>\n",
       "      <td>0.798935</td>\n",
       "      <td>0.088641</td>\n",
       "      <td>0.156792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.055800</td>\n",
       "      <td>0.128961</td>\n",
       "      <td>0.136943</td>\n",
       "      <td>0.704059</td>\n",
       "      <td>0.136943</td>\n",
       "      <td>0.228659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.041700</td>\n",
       "      <td>0.102654</td>\n",
       "      <td>0.162155</td>\n",
       "      <td>0.692670</td>\n",
       "      <td>0.162155</td>\n",
       "      <td>0.262337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.036100</td>\n",
       "      <td>0.086235</td>\n",
       "      <td>0.178609</td>\n",
       "      <td>0.697997</td>\n",
       "      <td>0.178609</td>\n",
       "      <td>0.283818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.034800</td>\n",
       "      <td>0.078116</td>\n",
       "      <td>0.178344</td>\n",
       "      <td>0.701534</td>\n",
       "      <td>0.178344</td>\n",
       "      <td>0.283735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.033400</td>\n",
       "      <td>0.075506</td>\n",
       "      <td>0.180467</td>\n",
       "      <td>0.701665</td>\n",
       "      <td>0.180467</td>\n",
       "      <td>0.286419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmp_count = 735 out of 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/new_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmp_count = 735 out of 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/new_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmp_count = 735 out of 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/new_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmp_count = 735 out of 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/new_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmp_count = 735 out of 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/new_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmp_count = 735 out of 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/new_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2676, training_loss=0.03972271846548859, metrics={'train_runtime': 184.9381, 'train_samples_per_second': 231.223, 'train_steps_per_second': 14.47, 'total_flos': 699786180693504.0, 'train_loss': 0.03972271846548859, 'epoch': 6.0})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define the training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",           # Output directory\n",
    "    evaluation_strategy=\"epoch\",      # Evaluate at the end of every epoch\n",
    "    learning_rate=2e-5,               # Learning rate\n",
    "    per_device_train_batch_size=16,   # Batch size for training\n",
    "    per_device_eval_batch_size=16,    # Batch size for evaluation\n",
    "    num_train_epochs=6,               # Number of training epochs\n",
    "    weight_decay=0.01,                # Weight decay\n",
    "    logging_dir='./logs',             # Directory for logging\n",
    ")\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=lora_model,                  # LoRA-wrapped model\n",
    "    args=training_args,                # Training arguments\n",
    "    train_dataset=tokenized_dataset['train'],  # Training dataset\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],  # Validation dataset (if available)\n",
    "    tokenizer=tokenizer,               # Tokenizer\n",
    "    compute_metrics=compute_metrics,  # model perfomance evaluation metric\n",
    ")\n",
    "\n",
    "# Fine-tune the model\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82880e92-4d83-442a-9a1c-3a2386b1c942",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: New York\n",
      "Predicted entities: New York\n",
      "\n",
      "Input: Los Angeles\n",
      "Predicted entities: Los Angeles\n",
      "\n",
      "Input: Chicago\n",
      "Predicted entities: Chicago\n",
      "\n",
      "Input: Philadelphia\n",
      "Predicted entities: Philadelphia\n",
      "\n",
      "Input: Dallas\n",
      "Predicted entities: Dallas\n",
      "\n",
      "Input: Fort Worth\n",
      "Predicted entities: Fort Worth\n",
      "\n",
      "Input: Houston\n",
      "Predicted entities: Houston\n",
      "\n",
      "Input: Atlanta\n",
      "Predicted entities: Atlanta\n",
      "\n",
      "Input: Boston\n",
      "Predicted entities: Boston\n",
      "\n",
      "Input: Manchester\n",
      "Predicted entities: Manchester\n",
      "\n",
      "Input: Washington, D.C.\n",
      "Predicted entities: Washington D . C\n",
      "\n",
      "Input: Hagerstown\n",
      "Predicted entities: Hagerstown\n",
      "\n",
      "Input: San Francisco\n",
      "Predicted entities: San Francisco\n",
      "\n",
      "Input: Oakland\n",
      "Predicted entities: Oakland\n",
      "\n",
      "Input: San Jose\n",
      "Predicted entities: San Jose\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Your text list\n",
    "text_list = [\n",
    "    'New York', 'Los Angeles', 'Chicago', 'Philadelphia', 'Dallas',\n",
    "    'Fort Worth', 'Houston', 'Atlanta', 'Boston', 'Manchester',\n",
    "    'Washington, D.C.', 'Hagerstown', 'San Francisco', 'Oakland',\n",
    "    'San Jose'\n",
    "]\n",
    "\n",
    "model = trainer.model\n",
    "\n",
    "# Function to make predictions and group entities\n",
    "def predict_ner(text_list):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    for text in text_list:\n",
    "        # Tokenize the input text\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "        \n",
    "        # Move inputs to the same device as the model\n",
    "        inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "        \n",
    "        # Perform inference\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        \n",
    "        # Get predictions (logits -> predicted labels)\n",
    "        predictions = torch.argmax(outputs.logits, dim=-1).cpu().numpy()[0]\n",
    "        \n",
    "        # Map the predictions to labels and tokens\n",
    "        tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0].cpu().numpy())\n",
    "        ner_labels = [model.config.id2label[pred] for pred in predictions]\n",
    "\n",
    "        # Group tokens back into entities\n",
    "        current_entity = []\n",
    "        current_label = None\n",
    "        entities = []\n",
    "\n",
    "        for token, label in zip(tokens, ner_labels):\n",
    "            # Ignore special tokens like [CLS], [SEP]\n",
    "            if token in [\"[CLS]\", \"[SEP]\"]:\n",
    "                continue\n",
    "            # Handle subword tokens (tokens starting with ##)\n",
    "            if token.startswith(\"##\"):\n",
    "                current_entity[-1] += token[2:]  # Append the subword without \"##\"\n",
    "            elif label.startswith(\"B-\") or (label.startswith(\"I-\") and label != current_label):\n",
    "                # New entity starts, append the old one\n",
    "                if current_entity:\n",
    "                    entities.append(\" \".join(current_entity))\n",
    "                    current_entity = []\n",
    "                current_entity.append(token)\n",
    "                current_label = label\n",
    "            elif label.startswith(\"I-\") and label == current_label:\n",
    "                # Continue current entity\n",
    "                current_entity.append(token)\n",
    "            else:\n",
    "                # Non-entity token or 'O'\n",
    "                if current_entity:\n",
    "                    entities.append(\" \".join(current_entity))\n",
    "                    current_entity = []\n",
    "                current_label = None\n",
    "\n",
    "        # Append any remaining entity\n",
    "        if current_entity:\n",
    "            entities.append(\" \".join(current_entity))\n",
    "\n",
    "        # Clean up tokens (remove subword tokens and punctuation issues, etc.)\n",
    "        clean_entities = []\n",
    "        for entity in entities:\n",
    "            entity = entity.replace(\" ##\", \"\")\n",
    "            entity = entity.replace(\" .\", \".\")  # Handle punctuation\n",
    "            entity = entity.replace(\" ,\", \",\")\n",
    "            clean_entities.append(entity)\n",
    "\n",
    "        # Print the result for comparison\n",
    "        print(f\"Input: {text}\")\n",
    "        print(f\"Predicted entities: {' '.join(clean_entities)}\")\n",
    "        print()\n",
    "\n",
    "# Run predictions on the text list\n",
    "predict_ner(text_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fdf1c664-80e1-47a1-a33f-98e2dd509623",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForTokenClassification, AutoTokenizer\n",
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "# Load the base model (DistilBERT NER model)\n",
    "base_model = AutoModelForTokenClassification.from_pretrained(\"dslim/distilbert-NER\")\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dslim/distilbert-NER\")\n",
    "\n",
    "# Load the LoRA-adapted model\n",
    "peft_config = PeftConfig.from_pretrained(\"results/checkpoint-2676\")\n",
    "lora_model = PeftModel.from_pretrained(base_model, \"results/checkpoint-2676\")\n",
    "\n",
    "# Merge the LoRA weights with the base model\n",
    "merged_model = lora_model.merge_and_unload()  # This merges LoRA into the base model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d9d63ba4-2659-44b6-bf40-e33cc1516545",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tmp/merged_distilbert_ner/tokenizer_config.json',\n",
       " 'tmp/merged_distilbert_ner/special_tokens_map.json',\n",
       " 'tmp/merged_distilbert_ner/vocab.txt',\n",
       " 'tmp/merged_distilbert_ner/added_tokens.json',\n",
       " 'tmp/merged_distilbert_ner/tokenizer.json')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the merged model and tokenizer\n",
    "save_dir = \"tmp/merged_distilbert_ner\"\n",
    "merged_model.save_pretrained(save_dir)\n",
    "tokenizer.save_pretrained(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "efae28df-7596-4142-9aa8-9e8e5d291f9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !huggingface-cli whoami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b73fbf99-9165-4afe-a34a-a7a112427371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !huggingface-cli login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0c889aa6-4b3d-479b-8dc7-23abf7a3164e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 261M/261M [00:07<00:00, 36.0MB/s] \n",
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/Mozilla/distilbert-NER-LoRA/commit/c2a46d9d4f2efe56a6cf6fd501e221be1438767a', commit_message='Upload tokenizer', commit_description='', oid='c2a46d9d4f2efe56a6cf6fd501e221be1438767a', pr_url=None, repo_url=RepoUrl('https://huggingface.co/Mozilla/distilbert-NER-LoRA', endpoint='https://huggingface.co', repo_type='model', repo_id='Mozilla/distilbert-NER-LoRA'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upload the merged model\n",
    "merged_model_dir = \"tmp/merged_distilbert_ner\"\n",
    "merged_repo_id = \"Mozilla/distilbert-NER-LoRA\"  # Adjust as needed\n",
    "\n",
    "merged_model.push_to_hub(merged_repo_id)\n",
    "tokenizer.push_to_hub(merged_repo_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012f08c0-2488-4efb-93b2-2d89a8ff6cc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "my_env",
   "name": ".m124",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/:m124"
  },
  "kernelspec": {
   "display_name": "Python (my_env) (Local)",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
