{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22bbbb75-8c65-440e-a059-c63c2fa91996",
   "metadata": {},
   "source": [
    "purpose of this notebook is to finetune the \"dslim/bert-base-NER\" model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7436463-26a4-4ebb-abd1-771ee134220b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/new_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "from transformers import TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6740344d-7d09-457a-bb68-a64f2b532103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'mps'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6093b56-0180-4b67-8b04-b562979979ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "full_dataset = Dataset.from_parquet(\"data/combined_ner_examples.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f06a123-bdd7-4655-ae16-92bdc655924f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'tokens', 'ner_tags'],\n",
       "    num_rows: 19041\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e5b0e6e-e169-4e32-aeae-00c58949ff32",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18041"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_set_size = 1000\n",
    "val_start = len(full_dataset) - val_set_size\n",
    "val_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd3d3524-3a60-4ce2-863b-08a6dadd2fcc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Split the dataset into train and validation sets\n",
    "train_dataset = full_dataset.select(range(val_start))  # Select training rows\n",
    "val_dataset = full_dataset.select(range(val_start, len(full_dataset)))  # Select last 1000 rows for validation\n",
    "\n",
    "# Combine them into a DatasetDict\n",
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'validation': val_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4ffc3cd-886d-4f7f-a8c8-8f5413628646",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags'],\n",
       "        num_rows: 18041\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "340175ec-d224-4c3b-aaa5-16037c61fff0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset['train'].to_pandas()['tokens'].apply(len).hist(bins=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2046667-d9ef-44ab-a444-dc95752478aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f20d0f6-fa8e-47d7-a60b-2e673e25685a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:00<00:00, 3788.68 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load the tokenizer for distilbert-based NER\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dslim/distilbert-NER\")\n",
    "\n",
    "# Function to tokenize the input and align labels with tokens\n",
    "def tokenize_and_align_labels(example):\n",
    "    # Tokenize 'tokens' while keeping track of word boundaries\n",
    "    tokenized_inputs = tokenizer(\n",
    "        example['tokens'], \n",
    "        is_split_into_words=True, \n",
    "        truncation=True, \n",
    "        padding='max_length',\n",
    "        max_length=64,\n",
    "    )\n",
    "    \n",
    "    # Get the word_ids (mapping from tokens to original words)\n",
    "    word_ids = tokenized_inputs.word_ids()\n",
    "    aligned_labels = []\n",
    "\n",
    "    previous_word_idx = None\n",
    "    for word_idx in word_ids:\n",
    "        if word_idx is None:\n",
    "            aligned_labels.append(-100)  # Special tokens ([CLS], [SEP], etc.)\n",
    "        elif word_idx != previous_word_idx:\n",
    "            aligned_labels.append(example['ner_tags'][word_idx])  # Assign the label to the first token of each word\n",
    "        else:\n",
    "            aligned_labels.append(-100)  # Subword tokens get label -100\n",
    "\n",
    "        previous_word_idx = word_idx\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = aligned_labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "# Apply the function to the dataset\n",
    "tokenized_dataset = dataset.map(tokenize_and_align_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "106935d0-9093-4ff9-8e0f-afe4aa2d792c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 18041\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "331d6dca-55d0-473e-94ca-90a152a9e9b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 18041,\n",
       " 'tokens': ['weather', 'chattanooga'],\n",
       " 'ner_tags': [0, 5],\n",
       " 'input_ids': [101,\n",
       "  4250,\n",
       "  13287,\n",
       "  26445,\n",
       "  23282,\n",
       "  102,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'labels': [-100,\n",
       "  0,\n",
       "  5,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset['validation'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1221fd4e-3f16-4ed4-9d9f-c359604545ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_predictions_and_labels(predictions, references):\n",
    "    true_predictions = []\n",
    "    true_labels = []\n",
    "    cmp_count = 0\n",
    "\n",
    "    for prediction, reference in zip(predictions, references):\n",
    "        # Only keep labels that are not -100\n",
    "        true_labels_example = [label for label in reference if label != -100]\n",
    "        \n",
    "        # Align predictions: Remove predictions for which the corresponding reference label is -100\n",
    "        true_predictions_example = [pred for pred, ref in zip(prediction, reference) if ref != -100]\n",
    "\n",
    "        # Ensure the length of predictions and labels matches\n",
    "        if len(true_predictions_example) == len(true_labels_example):\n",
    "            true_labels.append(true_labels_example)\n",
    "            true_predictions.append(true_predictions_example)\n",
    "            cmp_count += 1\n",
    "        else:\n",
    "            # Log or handle the error (example-level mismatch)\n",
    "            # print(f\"Skipping example due to mismatch: predictions ({len(true_predictions_example)}), labels ({len(true_labels_example)})\")\n",
    "            continue  # Skip this example\n",
    "\n",
    "    # Flatten the lists (convert from list of lists to a single list)\n",
    "    true_predictions = [pred for sublist in true_predictions for pred in sublist]\n",
    "    true_labels = [label for sublist in true_labels for label in sublist]\n",
    "    print(f\"cmp_count = {cmp_count} out of {len(predictions)}\")\n",
    "\n",
    "    return true_predictions, true_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f62dee2-077d-451f-af48-60eaf50e5edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    logits, labels = p\n",
    "    predictions = np.argmax(logits, axis=1)\n",
    "    \n",
    "    # Post-process the predictions and labels to remove -100 values\n",
    "    true_predictions, true_labels = postprocess_predictions_and_labels(predictions, labels)\n",
    "\n",
    "    # Combine metrics\n",
    "    accuracy_metric = evaluate.load(\"accuracy\")\n",
    "    precision_metric = evaluate.load(\"precision\")\n",
    "    recall_metric = evaluate.load(\"recall\")\n",
    "    f1_metric = evaluate.load(\"f1\")\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    precision = precision_metric.compute(predictions=true_predictions, references=true_labels, average=\"weighted\")\n",
    "    recall = recall_metric.compute(predictions=true_predictions, references=true_labels, average=\"weighted\")\n",
    "    f1 = f1_metric.compute(predictions=true_predictions, references=true_labels, average=\"weighted\")\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy[\"accuracy\"],\n",
    "        \"precision\": precision[\"precision\"],\n",
    "        \"recall\": recall[\"recall\"],\n",
    "        \"f1\": f1[\"f1\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f7acd16-763a-4055-b492-3007b5057da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load the pre-trained model\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"dslim/distilbert-NER\", num_labels=9)\n",
    "\n",
    "# Define the LoRA configuration\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.TOKEN_CLS,  # Task type is token classification (NER)\n",
    "    r=8,  # Low-rank dimension (you can experiment with this)\n",
    "    lora_alpha=32,  # Scaling factor for LoRA\n",
    "    lora_dropout=0.1,  # Dropout rate for LoRA\n",
    "    target_modules=['q_lin']  # LoRA is applied to query layer\n",
    ")\n",
    "\n",
    "# Apply LoRA to the model\n",
    "lora_model = get_peft_model(model, lora_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c185799-1fd7-4319-a2a5-89ba1ff52df1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/new_env/lib/python3.10/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11280' max='11280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11280/11280 12:05, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.055300</td>\n",
       "      <td>0.202098</td>\n",
       "      <td>0.137207</td>\n",
       "      <td>0.739245</td>\n",
       "      <td>0.137207</td>\n",
       "      <td>0.229643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.041600</td>\n",
       "      <td>0.121134</td>\n",
       "      <td>0.186188</td>\n",
       "      <td>0.731019</td>\n",
       "      <td>0.186188</td>\n",
       "      <td>0.295712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.035900</td>\n",
       "      <td>0.082461</td>\n",
       "      <td>0.215090</td>\n",
       "      <td>0.743112</td>\n",
       "      <td>0.215090</td>\n",
       "      <td>0.332553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.058815</td>\n",
       "      <td>0.226346</td>\n",
       "      <td>0.726689</td>\n",
       "      <td>0.226346</td>\n",
       "      <td>0.344456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.025600</td>\n",
       "      <td>0.045393</td>\n",
       "      <td>0.234560</td>\n",
       "      <td>0.731380</td>\n",
       "      <td>0.234560</td>\n",
       "      <td>0.354656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.025800</td>\n",
       "      <td>0.038766</td>\n",
       "      <td>0.238820</td>\n",
       "      <td>0.736664</td>\n",
       "      <td>0.238820</td>\n",
       "      <td>0.360281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.034672</td>\n",
       "      <td>0.240949</td>\n",
       "      <td>0.741062</td>\n",
       "      <td>0.240949</td>\n",
       "      <td>0.363298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.032483</td>\n",
       "      <td>0.236994</td>\n",
       "      <td>0.742275</td>\n",
       "      <td>0.236994</td>\n",
       "      <td>0.358985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.022200</td>\n",
       "      <td>0.031381</td>\n",
       "      <td>0.235777</td>\n",
       "      <td>0.743477</td>\n",
       "      <td>0.235777</td>\n",
       "      <td>0.357739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.023700</td>\n",
       "      <td>0.030968</td>\n",
       "      <td>0.234865</td>\n",
       "      <td>0.742627</td>\n",
       "      <td>0.234865</td>\n",
       "      <td>0.356574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmp_count = 563 out of 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/new_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmp_count = 563 out of 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/new_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmp_count = 563 out of 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/new_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmp_count = 563 out of 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/new_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmp_count = 563 out of 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/new_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmp_count = 563 out of 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/new_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmp_count = 563 out of 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/new_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmp_count = 563 out of 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/new_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmp_count = 563 out of 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/new_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmp_count = 563 out of 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/new_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=11280, training_loss=0.032516554949131415, metrics={'train_runtime': 725.3824, 'train_samples_per_second': 248.71, 'train_steps_per_second': 15.55, 'total_flos': 2952350798814720.0, 'train_loss': 0.032516554949131415, 'epoch': 10.0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define the training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",           # Output directory\n",
    "    evaluation_strategy=\"epoch\",      # Evaluate at the end of every epoch\n",
    "    learning_rate=2e-5,               # Learning rate\n",
    "    per_device_train_batch_size=16,   # Batch size for training\n",
    "    per_device_eval_batch_size=16,    # Batch size for evaluation\n",
    "    num_train_epochs=10,               # Number of training epochs\n",
    "    weight_decay=0.01,                # Weight decay\n",
    "    logging_dir='./logs',             # Directory for logging\n",
    ")\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=lora_model,                  # LoRA-wrapped model\n",
    "    args=training_args,                # Training arguments\n",
    "    train_dataset=tokenized_dataset['train'],  # Training dataset\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],  # Validation dataset (if available)\n",
    "    tokenizer=tokenizer,               # Tokenizer\n",
    "    compute_metrics=compute_metrics,  # model perfomance evaluation metric\n",
    ")\n",
    "\n",
    "# Fine-tune the model\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82880e92-4d83-442a-9a1c-3a2386b1c942",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] O\n",
      "New B-LOC\n",
      "York I-LOC\n",
      "[SEP] I-LOC\n",
      "Input: New York\n",
      "Predicted entities: New York\n",
      "\n",
      "[CLS] O\n",
      "Los B-LOC\n",
      "Angeles I-LOC\n",
      "[SEP] I-LOC\n",
      "Input: Los Angeles\n",
      "Predicted entities: Los Angeles\n",
      "\n",
      "[CLS] O\n",
      "Chicago B-LOC\n",
      "[SEP] O\n",
      "Input: Chicago\n",
      "Predicted entities: Chicago\n",
      "\n",
      "[CLS] O\n",
      "Philadelphia B-LOC\n",
      "[SEP] O\n",
      "Input: Philadelphia\n",
      "Predicted entities: Philadelphia\n",
      "\n",
      "[CLS] O\n",
      "Dallas B-LOC\n",
      "[SEP] O\n",
      "Input: Dallas\n",
      "Predicted entities: Dallas\n",
      "\n",
      "[CLS] O\n",
      "Fort B-LOC\n",
      "Worth I-LOC\n",
      "[SEP] I-LOC\n",
      "Input: Fort Worth\n",
      "Predicted entities: Fort Worth\n",
      "\n",
      "[CLS] O\n",
      "Houston B-LOC\n",
      "[SEP] O\n",
      "Input: Houston\n",
      "Predicted entities: Houston\n",
      "\n",
      "[CLS] O\n",
      "Atlanta B-LOC\n",
      "[SEP] O\n",
      "Input: Atlanta\n",
      "Predicted entities: Atlanta\n",
      "\n",
      "[CLS] O\n",
      "Boston B-LOC\n",
      "[SEP] O\n",
      "Input: Boston\n",
      "Predicted entities: Boston\n",
      "\n",
      "[CLS] O\n",
      "Manchester B-LOC\n",
      "[SEP] I-LOC\n",
      "Input: Manchester\n",
      "Predicted entities: Manchester\n",
      "\n",
      "[CLS] O\n",
      "Washington B-LOC\n",
      ", O\n",
      "D B-LOC\n",
      ". B-LOC\n",
      "C I-LOC\n",
      ". I-LOC\n",
      "[SEP] I-LOC\n",
      "Input: Washington, D.C.\n",
      "Predicted entities: Washington D . C.\n",
      "\n",
      "[CLS] O\n",
      "Ha B-LOC\n",
      "##gers B-LOC\n",
      "##town B-LOC\n",
      "[SEP] O\n",
      "Input: Hagerstown\n",
      "Predicted entities: Hagerstown\n",
      "\n",
      "[CLS] O\n",
      "San B-LOC\n",
      "Francisco I-LOC\n",
      "[SEP] I-LOC\n",
      "Input: San Francisco\n",
      "Predicted entities: San Francisco\n",
      "\n",
      "[CLS] O\n",
      "Oakland B-ORG\n",
      "[SEP] O\n",
      "Input: Oakland\n",
      "Predicted entities: Oakland\n",
      "\n",
      "[CLS] O\n",
      "San B-LOC\n",
      "Jose I-LOC\n",
      "[SEP] I-LOC\n",
      "Input: San Jose\n",
      "Predicted entities: San Jose\n",
      "\n",
      "[CLS] O\n",
      "weather O\n",
      "in O\n",
      "sa B-LOC\n",
      "##n B-LOC\n",
      "j I-LOC\n",
      "##ose B-LOC\n",
      "[SEP] O\n",
      "Input: weather in san jose\n",
      "Predicted entities: san jose\n",
      "\n",
      "[CLS] O\n",
      "weather O\n",
      "in O\n",
      "Boston B-LOC\n",
      "[SEP] O\n",
      "Input: weather in Boston\n",
      "Predicted entities: Boston\n",
      "\n",
      "[CLS] O\n",
      "Weather O\n",
      "in O\n",
      "Boston B-LOC\n",
      "[SEP] O\n",
      "Input: Weather in Boston\n",
      "Predicted entities: Boston\n",
      "\n",
      "[CLS] O\n",
      "weather O\n",
      "Boston B-LOC\n",
      "[SEP] O\n",
      "Input: weather Boston\n",
      "Predicted entities: Boston\n",
      "\n",
      "[CLS] O\n",
      "Weather O\n",
      "Boston B-LOC\n",
      "[SEP] O\n",
      "Input: Weather Boston\n",
      "Predicted entities: Boston\n",
      "\n",
      "[CLS] O\n",
      "weather O\n",
      "[SEP] O\n",
      "Input: weather\n",
      "Predicted entities: \n",
      "\n",
      "[CLS] O\n",
      "Weather O\n",
      "[SEP] O\n",
      "Input: Weather\n",
      "Predicted entities: \n",
      "\n",
      "[CLS] O\n",
      "Boston B-LOC\n",
      "weather O\n",
      "[SEP] O\n",
      "Input: Boston weather\n",
      "Predicted entities: Boston\n",
      "\n",
      "[CLS] O\n",
      "Boston B-LOC\n",
      "Weather I-LOC\n",
      "[SEP] I-LOC\n",
      "Input: Boston Weather\n",
      "Predicted entities: Boston Weather\n",
      "\n",
      "[CLS] O\n",
      "I O\n",
      "love O\n",
      "Pizza B-PER\n",
      "##hu B-PER\n",
      "##t B-PER\n",
      "[SEP] O\n",
      "Input: I love Pizzahut\n",
      "Predicted entities: Pizzahut\n",
      "\n",
      "[CLS] O\n",
      "I O\n",
      "like O\n",
      "Star B-ORG\n",
      "##bu B-ORG\n",
      "##cks B-ORG\n",
      "[SEP] O\n",
      "Input: I like Starbucks\n",
      "Predicted entities: Starbucks\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Your text list\n",
    "text_list = [\n",
    "    'New York', 'Los Angeles', 'Chicago', 'Philadelphia', 'Dallas',\n",
    "    'Fort Worth', 'Houston', 'Atlanta', 'Boston', 'Manchester',\n",
    "    'Washington, D.C.', 'Hagerstown', 'San Francisco', 'Oakland',\n",
    "    'San Jose', \n",
    "    # 'san jose',\n",
    "    'weather in san jose',\n",
    "    'weather in Boston',\n",
    "    'Weather in Boston',\n",
    "    'weather Boston',\n",
    "    'Weather Boston',\n",
    "    'weather',\n",
    "    'Weather',\n",
    "    'Boston weather',\n",
    "    'Boston Weather',\n",
    "    'I love Pizzahut',\n",
    "    'I like Starbucks',\n",
    "]\n",
    "\n",
    "model = trainer.model\n",
    "\n",
    "# Function to make predictions and group entities\n",
    "def predict_ner(text_list):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    for text in text_list:\n",
    "        # Tokenize the input text\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "        \n",
    "        # Move inputs to the same device as the model\n",
    "        inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "        \n",
    "        # Perform inference\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        \n",
    "        # Get predictions (logits -> predicted labels)\n",
    "        predictions = torch.argmax(outputs.logits, dim=-1).cpu().numpy()[0]\n",
    "        \n",
    "        # Map the predictions to labels and tokens\n",
    "        tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0].cpu().numpy())\n",
    "        ner_labels = [model.config.id2label[pred] for pred in predictions]\n",
    "\n",
    "        # Group tokens back into entities\n",
    "        current_entity = []\n",
    "        current_label = None\n",
    "        entities = []\n",
    "\n",
    "        for token, label in zip(tokens, ner_labels):\n",
    "            print(token, label)\n",
    "            # Ignore special tokens like [CLS], [SEP]\n",
    "            if token in [\"[CLS]\", \"[SEP]\"]:\n",
    "                continue\n",
    "            # Handle subword tokens (tokens starting with ##)\n",
    "            if token.startswith(\"##\"):\n",
    "                current_entity[-1] += token[2:]  # Append the subword without \"##\"\n",
    "            elif label.startswith(\"B-\") or (label.startswith(\"I-\") and label != current_label):\n",
    "                # New entity starts, append the old one\n",
    "                if current_entity:\n",
    "                    entities.append(\" \".join(current_entity))\n",
    "                    current_entity = []\n",
    "                current_entity.append(token)\n",
    "                current_label = label\n",
    "            elif label.startswith(\"I-\") and label == current_label:\n",
    "                # Continue current entity\n",
    "                current_entity.append(token)\n",
    "            else:\n",
    "                # Non-entity token or 'O'\n",
    "                if current_entity:\n",
    "                    entities.append(\" \".join(current_entity))\n",
    "                    current_entity = []\n",
    "                current_label = None\n",
    "\n",
    "        # Append any remaining entity\n",
    "        if current_entity:\n",
    "            entities.append(\" \".join(current_entity))\n",
    "\n",
    "        # Clean up tokens (remove subword tokens and punctuation issues, etc.)\n",
    "        clean_entities = []\n",
    "        for entity in entities:\n",
    "            entity = entity.replace(\" ##\", \"\")\n",
    "            entity = entity.replace(\" .\", \".\")  # Handle punctuation\n",
    "            entity = entity.replace(\" ,\", \",\")\n",
    "            clean_entities.append(entity)\n",
    "\n",
    "        # Print the result for comparison\n",
    "        print(f\"Input: {text}\")\n",
    "        print(f\"Predicted entities: {' '.join(clean_entities)}\")\n",
    "        print()\n",
    "\n",
    "# Run predictions on the text list\n",
    "predict_ner(text_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fdf1c664-80e1-47a1-a33f-98e2dd509623",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForTokenClassification, AutoTokenizer\n",
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "# Load the base model (DistilBERT NER model)\n",
    "base_model = AutoModelForTokenClassification.from_pretrained(\"dslim/distilbert-NER\")\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dslim/distilbert-NER\")\n",
    "\n",
    "# Load the LoRA-adapted model\n",
    "peft_config = PeftConfig.from_pretrained(\"results/checkpoint-11000\")\n",
    "lora_model = PeftModel.from_pretrained(base_model, \"results/checkpoint-11000\")\n",
    "\n",
    "# Merge the LoRA weights with the base model\n",
    "merged_model = lora_model.merge_and_unload()  # This merges LoRA into the base model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9d63ba4-2659-44b6-bf40-e33cc1516545",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tmp/merged_distilbert_ner/tokenizer_config.json',\n",
       " 'tmp/merged_distilbert_ner/special_tokens_map.json',\n",
       " 'tmp/merged_distilbert_ner/vocab.txt',\n",
       " 'tmp/merged_distilbert_ner/added_tokens.json',\n",
       " 'tmp/merged_distilbert_ner/tokenizer.json')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the merged model and tokenizer\n",
    "save_dir = \"tmp/merged_distilbert_ner\"\n",
    "merged_model.save_pretrained(save_dir)\n",
    "tokenizer.save_pretrained(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "efae28df-7596-4142-9aa8-9e8e5d291f9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !huggingface-cli whoami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b73fbf99-9165-4afe-a34a-a7a112427371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !huggingface-cli login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c889aa6-4b3d-479b-8dc7-23abf7a3164e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 261M/261M [00:07<00:00, 33.3MB/s] \n",
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/Mozilla/distilbert-NER-LoRA/commit/64135813ad788ebbb43f5b6be082066fe677750f', commit_message='Upload tokenizer', commit_description='', oid='64135813ad788ebbb43f5b6be082066fe677750f', pr_url=None, repo_url=RepoUrl('https://huggingface.co/Mozilla/distilbert-NER-LoRA', endpoint='https://huggingface.co', repo_type='model', repo_id='Mozilla/distilbert-NER-LoRA'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upload the merged model\n",
    "merged_model_dir = \"tmp/merged_distilbert_ner\"\n",
    "merged_repo_id = \"Mozilla/distilbert-NER-LoRA\"  # Adjust as needed\n",
    "\n",
    "merged_model.push_to_hub(merged_repo_id)\n",
    "tokenizer.push_to_hub(merged_repo_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012f08c0-2488-4efb-93b2-2d89a8ff6cc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "my_env",
   "name": ".m124",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/:m124"
  },
  "kernelspec": {
   "display_name": "Python (my_env) (Local)",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
